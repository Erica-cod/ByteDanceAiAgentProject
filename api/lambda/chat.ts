/**
 * Chat API - ç¬¦åˆ Modern.js BFF è§„èŒƒ
 * è·¯ç”±: /api/chat
 * 
 * æ”¯æŒæµå¼å“åº” (SSE)
 * 
 * âœ… é‡æ„åï¼šè·¯ç”±å±‚åªè´Ÿè´£å‚æ•°éªŒè¯ã€å¹¶å‘æ§åˆ¶ã€è·¯ç”±åˆ†å‘
 * âœ… å…·ä½“é€»è¾‘å·²æ‹†åˆ†åˆ°ç‹¬ç«‹æ¨¡å—
 */

// åŠ è½½ç¯å¢ƒå˜é‡
import '../config/env.js';
import { connectToDatabase } from '../db/connection.js';

// âœ… V2: åˆå§‹åŒ–å·¥å…·ç³»ç»Ÿ
import { initializeToolSystem } from '../tools/v2/index.js';

// åˆå§‹åŒ–æ ‡å¿—ï¼ˆç¡®ä¿åªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
let toolSystemInitialized = false;
if (!toolSystemInitialized) {
  initializeToolSystem();
  toolSystemInitialized = true;
}
import { errorResponse } from './_utils/response.js';
import { getCorsHeaders, handleOptionsRequest } from './_utils/cors.js';
import { acquireSSESlot } from '../_clean/infrastructure/streaming/sse-limiter.js';
import { getContainer } from '../_clean/di-container.js';
import { getRecommendedConfig } from '../config/memoryConfig.js';
import { SYSTEM_PROMPT } from '../config/systemPrompt.js';
import { callLocalModel, callVolcengineModel } from '../_clean/infrastructure/llm/model-service.js';
import { volcengineService } from '../_clean/infrastructure/llm/volcengine-service.js';
import { handleMultiAgentMode } from '../handlers/multiAgentHandler.js';
import { handleVolcanoStream, handleLocalStream } from '../handlers/singleAgentHandler.js';
import { handleResumeRequest } from '../handlers/resumeHandler.js';
import { handleCacheRequest } from '../handlers/cacheHandler.js';
import { SSEStreamWriter } from '../utils/sseStreamWriter.js';
import type { ChatRequestData, RequestOption } from '../types/chat.js';
import { gunzip } from 'zlib';
import { promisify } from 'util';

const gunzipAsync = promisify(gunzip);

// åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
connectToDatabase().catch(console.error);

/**
 * ç»Ÿä¸€è¿”å› 429ï¼ˆç”¨äºé™æµ/å¹¶å‘é™åˆ¶ï¼‰+ é˜Ÿåˆ—ä¿¡æ¯
 */
function tooManyRequests(
  message: string,
  retryAfterSec: number,
  requestOrigin?: string,
  queueToken?: string,
  queuePosition?: number,
  estimatedWaitSec?: number
) {
  const corsHeaders = getCorsHeaders(requestOrigin);
  
  const headers: Record<string, string> = {
    'Content-Type': 'application/json; charset=utf-8',
    'Retry-After': String(retryAfterSec),
    ...corsHeaders,
  };

  if (queueToken) headers['X-Queue-Token'] = queueToken;
  if (queuePosition !== undefined) headers['X-Queue-Position'] = String(queuePosition);
  if (estimatedWaitSec !== undefined) headers['X-Queue-Estimated-Wait'] = String(estimatedWaitSec);

  return new Response(JSON.stringify({ success: false, error: message }), {
    status: 429,
    headers,
  });
}

/**
 * OPTIONS /api/chat - å¤„ç†é¢„æ£€è¯·æ±‚
 */
export async function options({ headers }: RequestOption<any, any>) {
  const origin = headers?.origin;
  return handleOptionsRequest(origin);
}

/**
 * POST /api/chat - å‘é€èŠå¤©æ¶ˆæ¯ï¼ˆæµå¼å“åº”ï¼‰
 */
export async function post({
  data,
  headers,
}: RequestOption<any, ChatRequestData>) {
  try {
    const requestOrigin = headers?.origin;
    console.log('=== æ”¶åˆ°èŠå¤©è¯·æ±‚ ===');
    
    // âœ… ç±»å‹æ£€æŸ¥ï¼šç¡®ä¿ data å­˜åœ¨
    if (!data) {
      return errorResponse('è¯·æ±‚æ•°æ®ä¸èƒ½ä¸ºç©º', requestOrigin);
    }
    
    let {
      message,
      modelType,
      conversationId: reqConversationId,
      userId,
      deviceId,
      mode,
      clientUserMessageId,
      clientAssistantMessageId,
      queueToken,
      uploadSessionId,
      isCompressed,
      resumeFrom, // ç»­æµå‚æ•°ï¼š{ messageId, position }
    } = data;

    // âœ… Clean Architecture: å¤„ç†ä¸Šä¼ ä¼šè¯ï¼ˆå‹ç¼©æˆ–åˆ†ç‰‡ä¸Šä¼ ï¼‰
    if (uploadSessionId) {
      console.log(`ğŸ“¦ [Upload] æ£€æµ‹åˆ°ä¸Šä¼ ä¼šè¯: ${uploadSessionId}`);
      
      try {
        const container = getContainer();
        
        // ç»„è£…åˆ†ç‰‡
        const assembleChunksUseCase = container.getAssembleChunksUseCase();
        const assembled = await assembleChunksUseCase.execute(uploadSessionId);
        console.log(`ğŸ“¦ [Upload] ç»„è£…å®Œæˆ: ${assembled.length} bytes`);
        
        // å¦‚æœæ˜¯å‹ç¼©çš„ï¼Œè§£å‹
        if (isCompressed) {
          console.log(`ğŸ“¦ [Upload] æ­£åœ¨è§£å‹...`);
          const decompressed = await gunzipAsync(assembled);
          message = decompressed.toString('utf-8');
          console.log(`ğŸ“¦ [Upload] è§£å‹å®Œæˆ: ${message.length} å­—ç¬¦`);
        } else {
          message = assembled.toString('utf-8');
        }
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        const cleanupSessionUseCase = container.getCleanupSessionUseCase();
        await cleanupSessionUseCase.execute(uploadSessionId);
        console.log(`ğŸ“¦ [Upload] å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶`);
        
      } catch (error: any) {
        console.error(`âŒ [Upload] å¤„ç†ä¸Šä¼ ä¼šè¯å¤±è´¥:`, error);
        return errorResponse(`ä¸Šä¼ å¤„ç†å¤±è´¥: ${error.message}`, requestOrigin);
      }
    }

    console.log('è§£æåçš„ messageé•¿åº¦:', message?.length || 0);
    console.log('è§£æåçš„ modelType:', modelType);
    console.log('è§£æåçš„ conversationId:', reqConversationId);
    console.log('è§£æåçš„ userId:', userId);
    console.log('è§£æåçš„ deviceId:', deviceId || 'æœªæä¾›ï¼ˆé™çº§åˆ° userId)');
    console.log('è§£æåçš„ mode:', mode || 'single');

    // ==================== å‚æ•°éªŒè¯ ====================
    if (!message || !message.trim()) {
      console.log('æ¶ˆæ¯å†…å®¹ä¸ºç©º');
      return errorResponse('æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º', requestOrigin);
    }

    if (!userId) {
      return errorResponse('userId is required', requestOrigin);
    }

    // ==================== å¹¶å‘é™åˆ¶ï¼ˆSSEé•¿è¿æ¥å ä½ï¼‰====================
    const identityId = deviceId || userId;
    const slot = acquireSSESlot(identityId, queueToken);
    
    if (slot.ok === false) {
      console.warn('âš ï¸  SSE å¹¶å‘é™åˆ¶è§¦å‘ï¼Œå·²åŠ å…¥é˜Ÿåˆ—:', slot);
      return tooManyRequests(
        slot.reason,
        slot.retryAfterSec,
        requestOrigin,
        slot.queueToken,
        slot.queuePosition,
        slot.estimatedWaitSec
      );
    }

    // è·å– release å‡½æ•°
    const release = slot.release;

    // æ˜¯å¦å·²æŠŠ release"äº¤æ¥"ç»™æµå¼å¤„ç†
    let handoffToStream = false;

    try {
      // âœ… Clean Architecture: ç¡®ä¿ç”¨æˆ·å­˜åœ¨
      const container = getContainer();
      const getOrCreateUserUseCase = container.getGetOrCreateUserUseCase();
      await getOrCreateUserUseCase.execute(userId);

      // âœ… Clean Architecture: å¦‚æœæ²¡æœ‰ conversationIdï¼Œåˆ›å»ºæ–°å¯¹è¯
      let conversationId = reqConversationId;
      if (!conversationId) {
        const createConversationUseCase = container.getCreateConversationUseCase();
        const conversationEntity = await createConversationUseCase.execute(
          userId,
          message.slice(0, 50) + (message.length > 50 ? '...' : '')
        );
        conversationId = conversationEntity.conversationId;
        console.log('âœ… Created new conversation:', conversationId);
      }

      // ==================== ç»­æµè¯·æ±‚å¤„ç† ====================
      const resumeResponse = await handleResumeRequest(resumeFrom, release);
      if (resumeResponse) {
        handoffToStream = true;
        return resumeResponse;
      }

      // âœ… Clean Architecture: ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
      try {
        const createMessageUseCase = container.getCreateMessageUseCase();
        const updateConversationUseCase = container.getUpdateConversationUseCase();
        
        await createMessageUseCase.execute(
          conversationId,
          userId,
          'user',
          message,
          clientUserMessageId,
          modelType,
          undefined
        );
        
        const conversation = await container.getGetConversationUseCase().execute(conversationId, userId);
        if (conversation) {
          await updateConversationUseCase.execute(
            conversationId,
            userId,
            { messageCount: conversation.messageCount + 1 }
          );
        }
        
        console.log('âœ… User message saved to database');
      } catch (dbError) {
        console.error('âŒ Failed to save user message:', dbError);
        // ç»§ç»­å¤„ç†ï¼Œä¸é˜»æ­¢ AI å›å¤
      }

      // ==================== ç¼“å­˜æ£€æŸ¥ ====================
      const cacheResponse = await handleCacheRequest(
        message,
        userId,
        conversationId,
        modelType,
        mode,
        clientAssistantMessageId,
        release
      );
      if (cacheResponse) {
        handoffToStream = true;
        return cacheResponse;
      }

      // ==================== è¶…é•¿æ–‡æœ¬ Chunking æ¨¡å¼ ====================
      const { longTextMode, longTextOptions } = data!; // data å·²åœ¨ä¸Šé¢æ£€æŸ¥è¿‡
      
      // æ£€æµ‹æ˜¯å¦éœ€è¦ chunkingï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦å’Œæ¨¡å¼ï¼‰
      const shouldUseChunking = 
        longTextMode === 'plan_review' || 
        (longTextMode !== 'off' && (message.length > 12000 || message.split('\n').length > 1000));
      
      if (shouldUseChunking) {
        console.log('ğŸ“¦ [Chunking] å¯åŠ¨è¶…é•¿æ–‡æœ¬æ™ºèƒ½åˆ†æ®µå¤„ç†...');
        
        // åˆ›å»º SSE æµ
        const { readable, writable } = new TransformStream();
        const writer = writable.getWriter();
        const sseWriter = new SSEStreamWriter(writer);
        
        // âœ… ä½¿ç”¨å—æ§ SSE Writerï¼ˆchunkingæ¨¡å¼ä½¿ç”¨è¿œç¨‹é…ç½®ï¼‰
        const { createRemoteControlledWriter } = await import('../_clean/infrastructure/streaming/controlled-sse-writer.js');
        const controlledWriter = createRemoteControlledWriter(sseWriter);
        
        handoffToStream = true;
        
        // å¼‚æ­¥å¤„ç†
        (async () => {
          try {
            // å‘é€åˆå§‹åŒ–äº‹ä»¶ï¼ˆç›´æ¥å‘é€ï¼‰
            await controlledWriter.sendDirect({
              conversationId,
              type: 'init',
              mode: 'chunking',
            });
            
            // å¯åŠ¨å¿ƒè·³
            sseWriter.startHeartbeat(15000);
            
            // âœ… Clean Architecture: æ‰§è¡Œé•¿æ–‡æœ¬åˆ†æ
            const processLongTextAnalysisUseCase = container.getProcessLongTextAnalysisUseCase();
            await processLongTextAnalysisUseCase.execute(
              message,
              userId,
              conversationId,
              clientAssistantMessageId,
              modelType,
              sseWriter,
              longTextOptions
            );
            
            await sseWriter.close();
          } catch (error: any) {
            console.error('âŒ [Chunking] å¤„ç†å¤±è´¥:', error);
            
            if (!sseWriter.isClosed()) {
              await controlledWriter.sendDirect({ 
                error: error.message || 'è¶…é•¿æ–‡æœ¬å¤„ç†å¤±è´¥' 
              });
            }
            
            await sseWriter.close();
          } finally {
            slot.release();
          }
        })();
        
        const corsHeaders = getCorsHeaders(requestOrigin);
        return new Response(readable, {
          headers: {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            ...corsHeaders,
          },
        });
      }
      
      // ==================== å¤šAgentæ¨¡å¼ ====================
      if (mode === 'multi_agent') {
        console.log('ğŸ¤– [MultiAgent] å¯åŠ¨å¤šAgentåä½œæ¨¡å¼...');
        handoffToStream = true;
        return handleMultiAgentMode(
          message, 
          userId, 
          conversationId, 
          clientAssistantMessageId, 
          slot.release,
          data!.resumeFromRound // data å·²åœ¨ä¸Šé¢æ£€æŸ¥è¿‡
        );
      }

      // ==================== å•Agentæ¨¡å¼ ====================
      // âœ… V2: æ£€æŸ¥æ˜¯å¦å¯ç”¨ Function Calling
      const useV2 = process.env.TOOL_SYSTEM_V2 === 'true';
      console.log(`ğŸ”§ å·¥å…·ç³»ç»Ÿç‰ˆæœ¬: ${useV2 ? 'V2 (Function Calling)' : 'V1 (Prompt-based)'}`);

      // ğŸ†• ä½¿ç”¨æ–°çš„ Clean Architecture - Memory æ¨¡å—
      const memoryConfig = getRecommendedConfig(modelType);
      const getConversationContextUseCase = container.getGetConversationContextUseCase();
      
      console.log(`ğŸ§  è®°å¿†é…ç½®: çª—å£=${memoryConfig.windowSize}è½®, Tokené™åˆ¶=${memoryConfig.maxTokens}`);

      // âœ… V2: æ ¹æ®ç‰ˆæœ¬é€‰æ‹© System Prompt
      let systemPrompt: string;
      if (useV2) {
        const { SYSTEM_PROMPT_V2 } = await import('../config/systemPrompt.v2.js');
        systemPrompt = SYSTEM_PROMPT_V2;
      } else {
        systemPrompt = SYSTEM_PROMPT;
      }

      // æ„å»ºæ¶ˆæ¯å†å²ï¼ˆå¸¦ä¸Šä¸‹æ–‡è®°å¿†ï¼‰
      const contextResult = await getConversationContextUseCase.execute({
        conversationId,
        userId,
        currentMessage: message,
        systemPrompt: systemPrompt,
        config: memoryConfig,
      });
      
      const messages = contextResult.context;
      console.log(`ğŸ“š å·²åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡ï¼ŒåŒ…å« ${messages.length} æ¡æ¶ˆæ¯`);
      console.log(`ğŸ“Š è®°å¿†ç»Ÿè®¡: ${contextResult.stats.uniqueMessages} æ¡å”¯ä¸€æ¶ˆæ¯, é¢„ä¼° ${contextResult.stats.estimatedTokens} tokens`);

      // âœ… åˆ›å»º AbortControllerï¼ˆç”¨äºç”¨æˆ·æ–­è¿æ—¶ä¸­æ–­ä¸Šæ¸¸è¯·æ±‚ï¼‰
      // æ³¨æ„ï¼šæš‚ä¸å®ç°ï¼Œå› ä¸ºéœ€è¦åœ¨æ›´åº•å±‚ä¼ é€’ï¼Œç•™å¾…åç»­ä¼˜åŒ–
      // const abortController = new AbortController();
      
      // è°ƒç”¨æ¨¡å‹
      if (useV2) {
        // ==================== V2: Function Calling æ¨¡å¼ ====================
        const { callLocalModelV2, callVolcengineModelV2 } = await import('../_clean/infrastructure/llm/model-service.v2.js');
        const { handleLocalStreamV2, handleVolcanoStreamV2 } = await import('../handlers/singleAgentHandler.v2.js');
        const { toolRegistry } = await import('../tools/v2/index.js');

        // è·å–å·¥å…·å®šä¹‰
        const tools = toolRegistry.getAllSchemas();
        console.log(`ğŸ”§ ä¼ é€’ ${tools.length} ä¸ªå·¥å…·å®šä¹‰ç»™æ¨¡å‹`);

        if (modelType === 'local') {
          console.log('å¼€å§‹è°ƒç”¨æœ¬åœ°æ¨¡å‹ï¼ˆV2 - Function Callingï¼‰...');
          const stream = await callLocalModelV2(messages, { tools });
          handoffToStream = true;
          return handleLocalStreamV2(
            stream,
            conversationId,
            userId,
            modelType,
            messages,
            clientAssistantMessageId,
            slot.release,
            message
          );
        } else if (modelType === 'volcano') {
          console.log('==========================================');
          console.log('ğŸŒ‹ å¼€å§‹è°ƒç”¨ç«å±±å¼•æ“è±†åŒ…æ¨¡å‹ï¼ˆV2 - Function Callingï¼‰...');
          console.log('ğŸ”‘ ARK_API_KEY é…ç½®çŠ¶æ€:', volcengineService.isConfigured() ? 'å·²é…ç½®' : 'æœªé…ç½®');
          console.log('ğŸ¯ ç›®æ ‡æ¨¡å‹:', process.env.ARK_MODEL || 'doubao-1-5-thinking-pro-250415');
          console.log('==========================================');
          
          // æ£€æŸ¥é…ç½®
          if (!volcengineService.isConfigured()) {
            console.error('âŒ ç«å±±å¼•æ“ API æœªé…ç½®ï¼');
            return errorResponse('ç«å±±å¼•æ“ API æœªé…ç½®ï¼Œè¯·è®¾ç½® ARK_API_KEY ç¯å¢ƒå˜é‡', requestOrigin);
          }

          const stream = await callVolcengineModelV2(messages, { tools });
          console.log('âœ… å·²æ”¶åˆ°ç«å±±å¼•æ“çš„æµå¼å“åº”');
          
          handoffToStream = true;
          return handleVolcanoStreamV2(
            stream,
            conversationId,
            userId,
            modelType,
            messages,
            clientAssistantMessageId,
            slot.release,
            message
          );
        } else {
          return errorResponse('ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹', requestOrigin);
        }
      } else {
        // ==================== V1: Prompt-based æ¨¡å¼ ====================
        if (modelType === 'local') {
          console.log('å¼€å§‹è°ƒç”¨æœ¬åœ°æ¨¡å‹...');
          const stream = await callLocalModel(messages /* , abortController.signal */);
          handoffToStream = true;
          return handleLocalStream(
            stream,
            conversationId,
            userId,
            modelType,
            messages,
            clientAssistantMessageId,
            slot.release,
            message // ä¼ é€’åŸå§‹è¯·æ±‚æ–‡æœ¬ç”¨äºç¼“å­˜
          );
        } else if (modelType === 'volcano') {
          console.log('==========================================');
          console.log('ğŸŒ‹ å¼€å§‹è°ƒç”¨ç«å±±å¼•æ“è±†åŒ…æ¨¡å‹...');
          console.log('ğŸ”‘ ARK_API_KEY é…ç½®çŠ¶æ€:', volcengineService.isConfigured() ? 'å·²é…ç½®' : 'æœªé…ç½®');
          console.log('ğŸ¯ ç›®æ ‡æ¨¡å‹:', process.env.ARK_MODEL || 'doubao-1-5-thinking-pro-250415');
          console.log('==========================================');
          
          // æ£€æŸ¥é…ç½®
          if (!volcengineService.isConfigured()) {
            console.error('âŒ ç«å±±å¼•æ“ API æœªé…ç½®ï¼');
            return errorResponse('ç«å±±å¼•æ“ API æœªé…ç½®ï¼Œè¯·è®¾ç½® ARK_API_KEY ç¯å¢ƒå˜é‡', requestOrigin);
          }

          const stream = await callVolcengineModel(messages /* , abortController.signal */);
          console.log('âœ… å·²æ”¶åˆ°ç«å±±å¼•æ“çš„æµå¼å“åº”');
          
          handoffToStream = true;
          return handleVolcanoStream(
            stream,
            conversationId,
            userId,
            modelType,
            messages,
            clientAssistantMessageId,
            slot.release,
            message // ä¼ é€’åŸå§‹è¯·æ±‚æ–‡æœ¬ç”¨äºç¼“å­˜
          );
        } else {
          return errorResponse('ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹', requestOrigin);
        }
      }
    } finally {
      // âœ… æ²¡æœ‰è¿›å…¥æµå¼è¿”å›ï¼Œå°±åœ¨è¿™é‡Œé‡Šæ”¾åé¢ï¼ˆé¿å…æ³„æ¼ï¼‰
      if (!handoffToStream) {
        slot.release();
      }
    }
  } catch (error: any) {
    console.error('å¤„ç†èŠå¤©è¯·æ±‚å¤±è´¥:', error);
    // æ³¨æ„ï¼šè¿™é‡Œçš„ requestOrigin å¯èƒ½æœªå®šä¹‰ï¼ˆå¦‚æœå¼‚å¸¸å‘ç”Ÿåœ¨æ—©æœŸï¼‰
    const origin = (error as any).requestOrigin;
    return errorResponse(error.message || 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯', origin);
  }
}

