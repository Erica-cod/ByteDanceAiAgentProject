/**
 * Chunking è®¡åˆ’è¯„å®¡æœåŠ¡
 * å¤„ç†è¶…é•¿è®¡åˆ’æ–‡æœ¬çš„æ™ºèƒ½åˆ†æ®µåˆ†æ
 */

import { SSEStreamWriter } from '../utils/sseStreamWriter.js';
import { splitTextIntoChunks, type TextChunk } from '../utils/textChunker.js';
import { buildMapPrompt, buildReducePrompt } from '../config/chunkingPrompts.js';
import { callVolcengineModel } from './modelService.js';
import { volcengineService } from './volcengineService.js';
import { MessageService } from './messageService.js';
import { ConversationService } from './conversationService.js';
import { extractThinkingAndContent } from '../_clean/shared/utils/content-extractor.js';
import type { ChatMessage } from '../types/chat.js';

interface ChunkingOptions {
  maxChunks?: number;
  includeCitations?: boolean;
}

interface ExtractedData {
  goals: string[];
  milestones: string[];
  tasks: Array<{
    title: string;
    owner?: string;
    deadline?: string;
    dependsOn?: string;
  }>;
  metrics: string[];
  risks: Array<{
    risk: string;
    mitigation?: string;
  }>;
  unknowns: string[];
}

/**
 * å¤„ç†è¶…é•¿è®¡åˆ’æ–‡æœ¬çš„ chunking åˆ†æ
 */
export async function handleChunkingPlanReview(
  message: string,
  userId: string,
  conversationId: string,
  clientAssistantMessageId: string | undefined,
  modelType: 'local' | 'volcano',
  sseWriter: SSEStreamWriter,
  options: ChunkingOptions = {}
): Promise<void> {
  console.log('ğŸ“¦ [Chunking] å¼€å§‹å¤„ç†è¶…é•¿æ–‡æœ¬...');
  
  try {
    // 1. Splitï¼šåˆ‡åˆ†æ–‡æœ¬
    const chunks = splitTextIntoChunks(message, {
      maxChunks: options.maxChunks || 30,
    });
    
    await sseWriter.sendEvent({
      type: 'chunking_init',
      totalChunks: chunks.length,
      estimatedSeconds: chunks.length * 5, // ç²—ç•¥ä¼°ç®—ï¼šæ¯ä¸ª chunk 5 ç§’
    });
    
    // 2. Mapï¼šåˆ†ææ¯ä¸ª chunk
    const extractedDataList: ExtractedData[] = [];
    
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      // æ£€æŸ¥æµæ˜¯å¦å·²å…³é—­
      if (sseWriter.isClosed()) {
        console.log('âš ï¸  [Chunking] å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œåœæ­¢å¤„ç†');
        return;
      }
      
      await sseWriter.sendEvent({
        type: 'chunking_progress',
        stage: 'map',
        chunkIndex: i,
        totalChunks: chunks.length,
      });
      
      console.log(`ğŸ” [Chunking] åˆ†æç¬¬ ${i + 1}/${chunks.length} æ®µ...`);
      
      // è°ƒç”¨æ¨¡å‹åˆ†æè¿™ä¸ª chunk
      const chunkData = await processChunk(chunk, i, chunks.length);
      extractedDataList.push(chunkData);
      
      await sseWriter.sendEvent({
        type: 'chunking_chunk',
        chunkIndex: i,
        chunkSummary: chunkData.goals.join('; '),
      });
    }
    
    // 3. Reduceï¼šåˆå¹¶æ•°æ®
    await sseWriter.sendEvent({
      type: 'chunking_progress',
      stage: 'reduce',
    });
    
    console.log('ğŸ”„ [Chunking] åˆå¹¶åˆ†æç»“æœ...');
    const mergedData = mergeExtractedData(extractedDataList);
    
    // 4. Finalï¼šç”Ÿæˆæœ€ç»ˆè¯„å®¡ï¼ˆæµå¼è¾“å‡ºï¼‰
    await sseWriter.sendEvent({
      type: 'chunking_progress',
      stage: 'final',
    });
    
    console.log('ğŸ“ [Chunking] ç”Ÿæˆæœ€ç»ˆè¯„å®¡æŠ¥å‘Š...');
    
    const finalPrompt = buildReducePrompt(mergedData, message, chunks.length);
    const messages: ChatMessage[] = [
      { role: 'user', content: finalPrompt }
    ];
    
    const stream = await callVolcengineModel(messages);
    
    // æµå¼è¾“å‡ºæœ€ç»ˆç»“æœ
    let buffer = '';
    let accumulatedText = '';
    
    for await (const chunk of stream) {
      if (sseWriter.isClosed()) break;
      
      const chunkStr = chunk.toString();
      buffer += chunkStr;
      
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';
      
      for (const line of lines) {
        if (line.trim()) {
          const content = volcengineService.parseStreamLine(line);
          
          if (content) {
            accumulatedText += content;
            const { thinking, content: mainContent } = extractThinkingAndContent(accumulatedText);
            
            await sseWriter.sendEvent({
              content: mainContent,
              thinking: thinking || undefined,
            });
          }
          
          if (line.includes('[DONE]')) {
            console.log('âœ… [Chunking] æœ€ç»ˆè¯„å®¡å®Œæˆ');
            break;
          }
        }
      }
    }
    
    // ä¿å­˜åˆ°æ•°æ®åº“
    if (accumulatedText) {
      const { thinking, content } = extractThinkingAndContent(accumulatedText);
      await MessageService.addMessage(
        conversationId,
        userId,
        'assistant',
        content || accumulatedText,
        clientAssistantMessageId,
        thinking,
        modelType
      );
      await ConversationService.incrementMessageCount(conversationId, userId);
      console.log('âœ… [Chunking] æ¶ˆæ¯å·²ä¿å­˜åˆ°æ•°æ®åº“');
    }
    
  } catch (error: any) {
    console.error('âŒ [Chunking] å¤„ç†å¤±è´¥:', error);
    throw error;
  }
}

/**
 * å¤„ç†å•ä¸ª chunkï¼ˆè°ƒç”¨æ¨¡å‹æå–ç»“æ„åŒ–ä¿¡æ¯ï¼‰
 */
async function processChunk(
  chunk: TextChunk,
  chunkIndex: number,
  totalChunks: number
): Promise<ExtractedData> {
  const prompt = buildMapPrompt(chunk.content, chunkIndex, totalChunks);
  const messages: ChatMessage[] = [
    { role: 'user', content: prompt }
  ];
  
  try {
    const stream = await callVolcengineModel(messages);
    
    // æ¶ˆè´¹æµå¹¶æ‹¼æ¥å®Œæ•´å“åº”
    let fullResponse = '';
    let buffer = '';
    
    for await (const streamChunk of stream) {
      const chunkStr = streamChunk.toString();
      buffer += chunkStr;
      
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';
      
      for (const line of lines) {
        if (line.trim() && !line.includes('[DONE]')) {
          const content = volcengineService.parseStreamLine(line);
          if (content) {
            fullResponse += content;
          }
        }
      }
    }
    
    // è§£æ JSON
    const jsonMatch = fullResponse.match(/```json\s*([\s\S]*?)\s*```/);
    if (jsonMatch) {
      const jsonStr = jsonMatch[1];
      const parsed = JSON.parse(jsonStr);
      
      return {
        goals: parsed.extracted?.goals || [],
        milestones: parsed.extracted?.milestones || [],
        tasks: parsed.extracted?.tasks || [],
        metrics: parsed.extracted?.metrics || [],
        risks: parsed.extracted?.risks || [],
        unknowns: parsed.extracted?.unknowns || [],
      };
    }
    
    // é™çº§ï¼šå°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
    try {
      const parsed = JSON.parse(fullResponse);
      return {
        goals: parsed.extracted?.goals || [],
        milestones: parsed.extracted?.milestones || [],
        tasks: parsed.extracted?.tasks || [],
        metrics: parsed.extracted?.metrics || [],
        risks: parsed.extracted?.risks || [],
        unknowns: parsed.extracted?.unknowns || [],
      };
    } catch {
      console.warn(`âš ï¸  [Chunking] Chunk ${chunkIndex} JSON è§£æå¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®`);
      return {
        goals: [],
        milestones: [],
        tasks: [],
        metrics: [],
        risks: [],
        unknowns: [],
      };
    }
  } catch (error) {
    console.error(`âŒ [Chunking] Chunk ${chunkIndex} å¤„ç†å¤±è´¥:`, error);
    return {
      goals: [],
      milestones: [],
      tasks: [],
      metrics: [],
      risks: [],
      unknowns: [],
    };
  }
}

/**
 * åˆå¹¶å¤šä¸ª chunk çš„æå–æ•°æ®ï¼ˆå»é‡ + å½’ä¸€åŒ–ï¼‰
 */
function mergeExtractedData(dataList: ExtractedData[]): ExtractedData {
  const merged: ExtractedData = {
    goals: [],
    milestones: [],
    tasks: [],
    metrics: [],
    risks: [],
    unknowns: [],
  };
  
  // å»é‡è¾…åŠ©å‡½æ•°
  const normalize = (str: string) => str.trim().toLowerCase().replace(/\s+/g, ' ');
  
  const seenGoals = new Set<string>();
  const seenMilestones = new Set<string>();
  const seenMetrics = new Set<string>();
  const seenUnknowns = new Set<string>();
  const seenTaskTitles = new Set<string>();
  const seenRisks = new Set<string>();
  
  for (const data of dataList) {
    // åˆå¹¶ goals
    for (const goal of data.goals) {
      const key = normalize(goal);
      if (!seenGoals.has(key)) {
        seenGoals.add(key);
        merged.goals.push(goal);
      }
    }
    
    // åˆå¹¶ milestones
    for (const milestone of data.milestones) {
      const key = normalize(milestone);
      if (!seenMilestones.has(key)) {
        seenMilestones.add(key);
        merged.milestones.push(milestone);
      }
    }
    
    // åˆå¹¶ tasksï¼ˆæŒ‰ title å»é‡ï¼‰
    for (const task of data.tasks) {
      const key = normalize(task.title);
      if (!seenTaskTitles.has(key)) {
        seenTaskTitles.add(key);
        merged.tasks.push(task);
      }
    }
    
    // åˆå¹¶ metrics
    for (const metric of data.metrics) {
      const key = normalize(metric);
      if (!seenMetrics.has(key)) {
        seenMetrics.add(key);
        merged.metrics.push(metric);
      }
    }
    
    // åˆå¹¶ risks
    for (const risk of data.risks) {
      const key = normalize(risk.risk);
      if (!seenRisks.has(key)) {
        seenRisks.add(key);
        merged.risks.push(risk);
      }
    }
    
    // åˆå¹¶ unknowns
    for (const unknown of data.unknowns) {
      const key = normalize(unknown);
      if (!seenUnknowns.has(key)) {
        seenUnknowns.add(key);
        merged.unknowns.push(unknown);
      }
    }
  }
  
  console.log(`âœ… [Chunking] åˆå¹¶å®Œæˆ: ${merged.goals.length} ç›®æ ‡, ${merged.tasks.length} ä»»åŠ¡, ${merged.risks.length} é£é™©`);
  
  return merged;
}

