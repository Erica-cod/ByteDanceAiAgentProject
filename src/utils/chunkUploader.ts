/**
 * åˆ†ç‰‡ä¸Šä¼ å™¨ï¼ˆæ”¯æŒhashæ ¡éªŒã€æ–­ç‚¹ç»­ä¼ ã€å¤±è´¥é‡è¯•ï¼‰
 */

import { UPLOAD_THRESHOLDS } from '../constants/uploadThresholds';
import { calculateHash } from './compression';
import { fetchWithCsrf } from './fetchWithCsrf';

/**
 * åˆ†ç‰‡å…ƒæ•°æ®
 */
interface ChunkMetadata {
  index: number;
  size: number;
  hash: string;
  offset: number;
}

/**
 * ä¸Šä¼ ä¼šè¯çŠ¶æ€
 */
interface UploadSessionStatus {
  sessionId: string;
  totalChunks: number;
  uploadedChunks: number[];
  isComplete: boolean;
  failedChunks: number[];
}

/**
 * ä¸Šä¼ é€‰é¡¹
 */
interface UploadOptions {
  userId: string;
  onProgress?: (percent: number, uploaded: number, total: number) => void;
  onChunkComplete?: (chunkIndex: number, totalChunks: number) => void;
  onError?: (error: Error, chunkIndex?: number) => void;
  maxRetries?: number;  // æ¯ä¸ªåˆ†ç‰‡æœ€å¤§é‡è¯•æ¬¡æ•°
  existingSessionId?: string;  // æ–­ç‚¹ç»­ä¼ çš„ä¼šè¯ID
}

/**
 * åˆ†ç‰‡ä¸Šä¼ å™¨
 */
export class ChunkUploader {
  private static readonly CHUNK_SIZE = UPLOAD_THRESHOLDS.CHUNK_SIZE;
  private static readonly MAX_RETRIES = 3;
  private static readonly RETRY_DELAY = 1000; // 1ç§’

  /**
   * ä¸Šä¼ å¤§ Blobï¼ˆæ”¯æŒåˆ†ç‰‡ã€hashæ ¡éªŒã€æ–­ç‚¹ç»­ä¼ ï¼‰
   */
  static async uploadLargeBlob(
    blob: Blob,
    options: UploadOptions
  ): Promise<string> {
    const {
      userId,
      onProgress,
      onChunkComplete,
      onError,
      maxRetries = this.MAX_RETRIES,
      existingSessionId,
    } = options;

    const totalChunks = Math.ceil(blob.size / this.CHUNK_SIZE);
    
    console.log(`ğŸ“¦ å¼€å§‹åˆ†ç‰‡ä¸Šä¼ : ${totalChunks} ä¸ªåˆ†ç‰‡ï¼Œæ€»å¤§å° ${this.formatSize(blob.size)}`);
    
    let sessionId: string;
    let uploadedChunks: number[] = [];
    
    // æ£€æŸ¥æ˜¯å¦æœ‰å·²æœ‰ä¼šè¯ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    if (existingSessionId) {
      try {
        const status = await this.getUploadStatus(existingSessionId);
        if (status && !status.isComplete) {
          sessionId = existingSessionId;
          uploadedChunks = status.uploadedChunks;
          console.log(`ğŸ”„ ç»­ä¼ : å·²ä¸Šä¼  ${uploadedChunks.length}/${totalChunks} ä¸ªåˆ†ç‰‡`);
        } else {
          sessionId = await this.createSession(userId, totalChunks, blob.size);
        }
      } catch (error) {
        console.warn('âš ï¸ è·å–ä¼šè¯çŠ¶æ€å¤±è´¥ï¼Œåˆ›å»ºæ–°ä¼šè¯', error);
        sessionId = await this.createSession(userId, totalChunks, blob.size);
      }
    } else {
      sessionId = await this.createSession(userId, totalChunks, blob.size);
    }
    
    // ä¸Šä¼ æ‰€æœ‰åˆ†ç‰‡
    const failedChunks: number[] = [];
    
    for (let i = 0; i < totalChunks; i++) {
      // è·³è¿‡å·²ä¸Šä¼ çš„åˆ†ç‰‡
      if (uploadedChunks.includes(i)) {
        console.log(`â­ï¸ è·³è¿‡åˆ†ç‰‡ ${i + 1}/${totalChunks}`);
        onProgress?.(
          Math.round(((i + 1) / totalChunks) * 100),
          i + 1,
          totalChunks
        );
        continue;
      }
      
      const start = i * this.CHUNK_SIZE;
      const end = Math.min(start + this.CHUNK_SIZE, blob.size);
      const chunk = blob.slice(start, end);
      
      try {
        // è®¡ç®—åˆ†ç‰‡hash
        const hash = await calculateHash(chunk);
        
        // ä¸Šä¼ åˆ†ç‰‡ï¼ˆå¸¦é‡è¯•ï¼‰
        await this.uploadChunkWithRetry(
          sessionId,
          i,
          chunk,
          hash,
          maxRetries
        );
        
        onChunkComplete?.(i, totalChunks);
        onProgress?.(
          Math.round(((i + 1) / totalChunks) * 100),
          i + 1,
          totalChunks
        );
        
      } catch (error) {
        console.error(`âŒ åˆ†ç‰‡ ${i + 1}/${totalChunks} ä¸Šä¼ å¤±è´¥:`, error);
        failedChunks.push(i);
        onError?.(error as Error, i);
        
        // å¦‚æœå¤±è´¥çš„åˆ†ç‰‡å¤ªå¤šï¼Œç›´æ¥å–æ¶ˆæ•´ä¸ªä¸Šä¼ 
        if (failedChunks.length > Math.max(1, totalChunks * 0.1)) {
          throw new Error(
            `ä¸Šä¼ å¤±è´¥ï¼š${failedChunks.length} ä¸ªåˆ†ç‰‡å¤±è´¥ã€‚` +
            `å†…å®¹å¯èƒ½å¤ªå¤§ï¼Œè¯·å°è¯•å‡å°‘å†…å®¹åé‡æ–°å‘é€ã€‚`
          );
        }
      }
    }
    
    // å¦‚æœæœ‰å¤±è´¥çš„åˆ†ç‰‡ï¼ŒæŠ›å‡ºé”™è¯¯
    if (failedChunks.length > 0) {
      throw new Error(
        `ä¸Šä¼ å¤±è´¥ï¼š${failedChunks.length} ä¸ªåˆ†ç‰‡å¤±è´¥ï¼ˆåˆ†ç‰‡ç´¢å¼•ï¼š${failedChunks.join(', ')}ï¼‰ã€‚` +
        `è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å°è¯•å‡å°‘å†…å®¹åé‡æ–°å‘é€ã€‚`
      );
    }
    
    // å®Œæˆä¸Šä¼ 
    await this.completeUpload(sessionId);
    
    console.log(`âœ… åˆ†ç‰‡ä¸Šä¼ å®Œæˆ: sessionId=${sessionId}`);
    
    return sessionId;
  }
  
  /**
   * åˆ›å»ºä¸Šä¼ ä¼šè¯
   */
  private static async createSession(
    userId: string,
    totalChunks: number,
    fileSize: number
  ): Promise<string> {
    const response = await fetchWithCsrf('/api/upload/session', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        userId,
        totalChunks,
        fileSize,
        chunkSize: this.CHUNK_SIZE,
      }),
    });
    
    if (!response.ok) {
      throw new Error(`åˆ›å»ºä¸Šä¼ ä¼šè¯å¤±è´¥: ${response.status}`);
    }
    
    const data = await response.json();
    return data.sessionId;
  }
  
  /**
   * ä¸Šä¼ å•ä¸ªåˆ†ç‰‡ï¼ˆå¸¦é‡è¯•ï¼‰
   */
  private static async uploadChunkWithRetry(
    sessionId: string,
    chunkIndex: number,
    chunk: Blob,
    hash: string,
    maxRetries: number
  ): Promise<void> {
    let lastError: Error | null = null;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        if (attempt > 0) {
          console.log(`ğŸ”„ é‡è¯•åˆ†ç‰‡ ${chunkIndex}ï¼Œç¬¬ ${attempt}/${maxRetries} æ¬¡...`);
          await this.delay(this.RETRY_DELAY * attempt);
        }
        
        await this.uploadChunk(sessionId, chunkIndex, chunk, hash);
        return; // æˆåŠŸï¼Œé€€å‡º
        
      } catch (error) {
        lastError = error as Error;
        console.warn(`âš ï¸ åˆ†ç‰‡ ${chunkIndex} ç¬¬ ${attempt + 1} æ¬¡å°è¯•å¤±è´¥:`, error);
      }
    }
    
    // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
    throw new Error(
      `åˆ†ç‰‡ ${chunkIndex} ä¸Šä¼ å¤±è´¥ï¼ˆé‡è¯• ${maxRetries} æ¬¡åä»å¤±è´¥ï¼‰: ${lastError?.message}`
    );
  }
  
  /**
   * ä¸Šä¼ å•ä¸ªåˆ†ç‰‡
   */
  private static async uploadChunk(
    sessionId: string,
    chunkIndex: number,
    chunk: Blob,
    hash: string
  ): Promise<void> {
    const formData = new FormData();
    formData.append('sessionId', sessionId);
    formData.append('chunkIndex', chunkIndex.toString());
    formData.append('chunk', chunk);
    formData.append('hash', hash);
    
    const response = await fetchWithCsrf('/api/upload/chunk', {
      method: 'POST',
      body: formData,
    });
    
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(
        errorData.error || `ä¸Šä¼ åˆ†ç‰‡å¤±è´¥: ${response.status}`
      );
    }
    
    const data = await response.json();
    
    // æœåŠ¡å™¨ä¼šè¿”å›hashæ ¡éªŒç»“æœ
    if (!data.verified) {
      throw new Error('åˆ†ç‰‡hashæ ¡éªŒå¤±è´¥');
    }
  }
  
  /**
   * è·å–ä¸Šä¼ çŠ¶æ€
   */
  private static async getUploadStatus(
    sessionId: string
  ): Promise<UploadSessionStatus | null> {
    const response = await fetch(`/api/upload/status/${sessionId}`);
    
    if (!response.ok) {
      return null;
    }
    
    return response.json();
  }
  
  /**
   * å®Œæˆä¸Šä¼ 
   */
  private static async completeUpload(sessionId: string): Promise<void> {
    const response = await fetchWithCsrf('/api/upload/complete', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ sessionId }),
    });
    
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(
        errorData.error || `å®Œæˆä¸Šä¼ å¤±è´¥: ${response.status}`
      );
    }
  }
  
  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  /**
   * æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
   */
  private static formatSize(bytes: number): string {
    if (bytes < 1024) return `${bytes}B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)}KB`;
    return `${(bytes / 1024 / 1024).toFixed(1)}MB`;
  }
}

