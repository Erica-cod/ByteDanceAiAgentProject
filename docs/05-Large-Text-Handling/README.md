# ğŸ“ 05-Large-Text-Handlingï¼ˆå¤§æ–‡æœ¬å¤„ç†ï¼‰

## ğŸ“Œ æ¨¡å—ç®€ä»‹

æœ¬æ–‡ä»¶å¤¹åŒ…å«äº†è¶…å¤§æ–‡æœ¬å¤„ç†çš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚å¦‚ä½•åœ¨æµè§ˆå™¨ä¸­å¤„ç† 10MB+ã€100,000+ å­—çš„æ–‡æœ¬ï¼Ÿå¦‚ä½•å®ç°åˆ†å—ä¸Šä¼ ã€æ–­ç‚¹ç»­ä¼ ã€æ¸è¿›å¼åŠ è½½ï¼Ÿè¿™æ˜¯é¡¹ç›®ä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„æŠ€æœ¯ä¹‹ä¸€ã€‚

## ğŸ“š æ ¸å¿ƒæ–‡æ¡£

### â­ å®Œæ•´æ–¹æ¡ˆ

#### 1. COMPLETE_LARGE_TEXT_SOLUTION.mdï¼ˆ29KBï¼‰â­â­
**å®Œæ•´çš„å¤§æ–‡æœ¬è§£å†³æ–¹æ¡ˆ**

è¿™æ˜¯æœ¬æ¨¡å—çš„æ ¸å¿ƒæ–‡æ¡£ï¼ŒåŒ…å«äº†ä»é—®é¢˜å‘ç°åˆ°æœ€ç»ˆå®ç°çš„å®Œæ•´å†ç¨‹ã€‚

**æ ¸å¿ƒé—®é¢˜ï¼š**
- ğŸ“¤ **ä¸Šä¼ é—®é¢˜**ï¼š10MB æ–‡æœ¬ä¸Šä¼ å¤±è´¥
- ğŸ’¾ **å­˜å‚¨é—®é¢˜**ï¼šLocalStorage 5MB é™åˆ¶
- ğŸ–¥ï¸ **æ¸²æŸ“é—®é¢˜**ï¼š100,000+ å­—å¯¼è‡´æµè§ˆå™¨å¡æ­»
- ğŸ”„ **æ¢å¤é—®é¢˜**ï¼šä¸Šä¼ ä¸­æ–­åå¦‚ä½•ç»­ä¼ 

**å®Œæ•´æ–¹æ¡ˆï¼š**
```
å¤§æ–‡æœ¬å¤„ç†æµç¨‹
    â†“
1. æ£€æµ‹æ–‡æœ¬å¤§å°
    â†“
2. é€‰æ‹©ç­–ç•¥ (< 1MB: ç›´æ¥å‘é€ | > 1MB: åˆ†å—å¤„ç†)
    â†“
3. åˆ†å— + å‹ç¼©
    â†“
4. åˆ†å—ä¸Šä¼  (å¸¦è¿›åº¦æ˜¾ç¤º)
    â†“
5. æœåŠ¡ç«¯é‡ç»„
    â†“
6. æ¸è¿›å¼åŠ è½½æ˜¾ç¤º
```

**æŠ€æœ¯æ ˆï¼š**
- **å‹ç¼©**ï¼špako (gzip)
- **åˆ†å—**ï¼šè‡ªå®šä¹‰åˆ†å—ç®—æ³•
- **ä¸Šä¼ **ï¼šFormData + fetch
- **å­˜å‚¨**ï¼šIndexedDB
- **æ¸²æŸ“**ï¼šReact Virtuoso

#### 2. PROGRESSIVE_UPLOAD_STRATEGY.mdï¼ˆ26KBï¼‰â­â­
**æ¸è¿›å¼ä¸Šä¼ ç­–ç•¥**

**åˆ†å—ç­–ç•¥ï¼š**
```typescript
// åŠ¨æ€åˆ†å—å¤§å°
const getChunkSize = (totalSize: number) => {
  if (totalSize < 1MB) return totalSize; // ä¸åˆ†å—
  if (totalSize < 10MB) return 512KB;    // 512KB/å—
  if (totalSize < 100MB) return 1MB;     // 1MB/å—
  return 2MB;                            // 2MB/å—
};

// åˆ†å—ä¸Šä¼ 
const uploadChunks = async (file: File) => {
  const chunkSize = getChunkSize(file.size);
  const totalChunks = Math.ceil(file.size / chunkSize);
  
  for (let i = 0; i < totalChunks; i++) {
    const chunk = file.slice(
      i * chunkSize,
      (i + 1) * chunkSize
    );
    
    await uploadChunk({
      chunk,
      index: i,
      total: totalChunks,
      uploadId
    });
    
    // æ›´æ–°è¿›åº¦
    onProgress((i + 1) / totalChunks * 100);
  }
};
```

**æ–­ç‚¹ç»­ä¼ ï¼š**
```typescript
// ä¿å­˜ä¸Šä¼ è¿›åº¦
const saveProgress = (uploadId: string, chunkIndex: number) => {
  localStorage.setItem(`upload_${uploadId}`, JSON.stringify({
    chunkIndex,
    timestamp: Date.now()
  }));
};

// æ¢å¤ä¸Šä¼ 
const resumeUpload = async (uploadId: string) => {
  const progress = getProgress(uploadId);
  if (!progress) return startNewUpload();
  
  // ä»ä¸­æ–­ç‚¹ç»§ç»­
  return continueUpload(uploadId, progress.chunkIndex);
};
```

#### 3. COMPRESSION_VS_CHUNKING_ANALYSIS.mdï¼ˆ21KBï¼‰
**å‹ç¼© vs åˆ†å—çš„åˆ†æå¯¹æ¯”**

**å¯¹æ¯”è¡¨ï¼š**
| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **ä»…å‹ç¼©** | ç®€å•ã€å¿«é€Ÿ | å¤§æ–‡ä»¶ä»å¯èƒ½å¤±è´¥ | < 5MB |
| **ä»…åˆ†å—** | å¯é æ€§é«˜ | ç½‘ç»œä¼ è¾“é‡å¤§ | ç¨³å®šç½‘ç»œ |
| **å‹ç¼©+åˆ†å—** | ä¼ è¾“é‡å°ã€å¯é  | å®ç°å¤æ‚ | > 5MB â­ |

**æœ€ç»ˆé€‰æ‹©ï¼šå‹ç¼© + åˆ†å—**
```typescript
// 1. å…ˆå‹ç¼©
const compressed = await pako.gzip(text);

// 2. å†åˆ†å—
const chunks = splitIntoChunks(compressed, chunkSize);

// 3. é€å—ä¸Šä¼ 
for (const chunk of chunks) {
  await uploadChunk(chunk);
}
```

**å‹ç¼©æ•ˆæœï¼š**
- ğŸ“Š çº¯æ–‡æœ¬ï¼šå‹ç¼©ç‡ 70-80%
- ğŸ“Š JSON æ•°æ®ï¼šå‹ç¼©ç‡ 60-70%
- ğŸ“Š ä»£ç æ–‡ä»¶ï¼šå‹ç¼©ç‡ 65-75%
- ğŸ“Š å¹³å‡æå‡ï¼šèŠ‚çœ 70% ç½‘ç»œä¼ è¾“

### ğŸ“‹ æ¸è¿›å¼åŠ è½½

#### 4. PROGRESSIVE_MESSAGE_LOADING.mdï¼ˆ23KBï¼‰â­
**æ¸è¿›å¼æ¶ˆæ¯åŠ è½½**

**é—®é¢˜ï¼š**
- ä¸€æ¬¡æ€§åŠ è½½ 10,000+ æ¡æ¶ˆæ¯å¯¼è‡´å¡é¡¿
- é•¿æ¶ˆæ¯ï¼ˆ100KB+ï¼‰æ¸²æŸ“æ…¢
- å†…å­˜å ç”¨è¿‡é«˜

**è§£å†³æ–¹æ¡ˆï¼š**
```typescript
// 1. è™šæ‹ŸåŒ–åˆ—è¡¨
import { Virtuoso } from 'react-virtuoso';

<Virtuoso
  data={messages}
  itemContent={(index, message) => (
    <MessageItem message={message} />
  )}
  initialTopMostItemIndex={messages.length - 1}
/>

// 2. æ‡’åŠ è½½æ¶ˆæ¯å†…å®¹
const MessageContent = ({ messageId }) => {
  const [content, setContent] = useState('');
  
  useEffect(() => {
    // åªåŠ è½½å¯è§æ¶ˆæ¯çš„å†…å®¹
    loadMessageContent(messageId).then(setContent);
  }, [messageId]);
  
  return <div>{content}</div>;
};

// 3. åˆ†é¡µåŠ è½½å†å²
const loadMore = async () => {
  const olderMessages = await fetchMessages({
    before: firstMessageId,
    limit: 50
  });
  
  setMessages(prev => [...olderMessages, ...prev]);
};
```

#### 5. LARGE_MESSAGE_PERFORMANCE_OPTIMIZATION.mdï¼ˆ19KBï¼‰
**å¤§æ¶ˆæ¯æ€§èƒ½ä¼˜åŒ–**

**ä¼˜åŒ–ç­–ç•¥ï¼š**
1. **å†…å®¹æŠ˜å **ï¼šè¶…è¿‡ 1000 å­—è‡ªåŠ¨æŠ˜å 
2. **è™šæ‹Ÿæ»šåŠ¨**ï¼šåªæ¸²æŸ“å¯è§éƒ¨åˆ†
3. **å»¶è¿Ÿæ¸²æŸ“**ï¼šéå¯è§æ¶ˆæ¯å»¶è¿Ÿæ¸²æŸ“
4. **å†…å®¹åˆ†é¡µ**ï¼šè¶…é•¿å†…å®¹åˆ†é¡µæ˜¾ç¤º

```typescript
// å†…å®¹æŠ˜å 
const LargeMessage = ({ content }) => {
  const [expanded, setExpanded] = useState(false);
  const isLarge = content.length > 1000;
  
  return (
    <div>
      <div>
        {expanded || !isLarge 
          ? content 
          : content.slice(0, 1000) + '...'}
      </div>
      
      {isLarge && (
        <button onClick={() => setExpanded(!expanded)}>
          {expanded ? 'æ”¶èµ·' : 'å±•å¼€å…¨éƒ¨'}
        </button>
      )}
    </div>
  );
};
```

### ğŸ”§ æŠ€æœ¯å®ç°

#### 6. FILE_SYSTEM_RESUME_IMPLEMENTATION.mdï¼ˆ28KBï¼‰â­
**æ–‡ä»¶ç³»ç»Ÿæ¢å¤å®ç°**

**ä½¿ç”¨ IndexedDB æ›¿ä»£ LocalStorageï¼š**
```typescript
// IndexedDB æ“ä½œ
const db = await openDB('ChatDB', 1, {
  upgrade(db) {
    db.createObjectStore('messages');
    db.createObjectStore('uploads');
  }
});

// å­˜å‚¨å¤§æ–‡æœ¬
await db.put('messages', largeMessage, messageId);

// è¯»å–
const message = await db.get('messages', messageId);
```

**ä¼˜åŠ¿ï¼š**
- âœ… æ— å¤§å°é™åˆ¶ï¼ˆç†è®ºä¸Šæ— é™ï¼‰
- âœ… æ”¯æŒ Blob å’Œ ArrayBuffer
- âœ… å¼‚æ­¥æ“ä½œä¸é˜»å¡ UI
- âœ… äº‹åŠ¡æ”¯æŒä¿è¯æ•°æ®ä¸€è‡´æ€§

#### 7. CHUNKING_FAULT_TOLERANCE_GUIDE.mdï¼ˆ28KBï¼‰â­
**åˆ†å—å®¹é”™æŒ‡å—**

**å®¹é”™æœºåˆ¶ï¼š**
```typescript
// é‡è¯•æœºåˆ¶
const uploadWithRetry = async (chunk, maxRetries = 3) => {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await uploadChunk(chunk);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      
      // æŒ‡æ•°é€€é¿
      await sleep(Math.pow(2, i) * 1000);
    }
  }
};

// æ ¡éªŒæœºåˆ¶
const verifyChunk = async (chunkId: string) => {
  const response = await fetch(`/api/upload/verify/${chunkId}`);
  return response.json(); // { success: true, checksum: '...' }
};

// é”™è¯¯æ¢å¤
const handleUploadError = async (error, context) => {
  // 1. æ£€æŸ¥å“ªäº›å—å·²æˆåŠŸ
  const uploaded = await getUploadedChunks(context.uploadId);
  
  // 2. åªé‡ä¼ å¤±è´¥çš„å—
  const failed = context.allChunks.filter(
    chunk => !uploaded.includes(chunk.id)
  );
  
  // 3. é‡æ–°ä¸Šä¼ 
  for (const chunk of failed) {
    await uploadWithRetry(chunk);
  }
};
```

### ğŸ“– å…¶ä»–æ–‡æ¡£

#### 8. CHUNKING_RESUME_STRATEGY.mdï¼ˆ21KBï¼‰
åˆ†å—æ¢å¤ç­–ç•¥

#### 9. CHUNKING_STORAGE_OPTIONS.mdï¼ˆ16KBï¼‰
åˆ†å—å­˜å‚¨æ–¹æ¡ˆå¯¹æ¯”

#### 10. LARGE_TEXT_UPLOAD_OPTIMIZATION.mdï¼ˆ20KBï¼‰
å¤§æ–‡æœ¬ä¸Šä¼ ä¼˜åŒ–

#### 11. LONG_TEXT_CHUNKING_GUIDE.mdï¼ˆ8KBï¼‰
é•¿æ–‡æœ¬åˆ†å—æŒ‡å—

#### 12. CHUNKING_IMPLEMENTATION_SUMMARY.mdï¼ˆ10KBï¼‰
åˆ†å—å®ç°æ€»ç»“

## ğŸ¯ å…³é”®æŠ€æœ¯ç‚¹

### é˜ˆå€¼è®¾è®¡

```typescript
// æ™ºèƒ½é˜ˆå€¼
const THRESHOLDS = {
  DIRECT_SEND: 1 * 1024 * 1024,      // 1MB: ç›´æ¥å‘é€
  COMPRESS: 5 * 1024 * 1024,         // 5MB: å‹ç¼©åå‘é€
  CHUNK: 10 * 1024 * 1024,           // 10MB: åˆ†å—ä¸Šä¼ 
  MAX_SIZE: 100 * 1024 * 1024        // 100MB: æœ€å¤§é™åˆ¶
};

const selectStrategy = (size: number) => {
  if (size < THRESHOLDS.DIRECT_SEND) return 'direct';
  if (size < THRESHOLDS.COMPRESS) return 'compress';
  if (size < THRESHOLDS.CHUNK) return 'chunk';
  if (size < THRESHOLDS.MAX_SIZE) return 'chunk_compress';
  throw new Error('File too large');
};
```

### è¿›åº¦æ˜¾ç¤º

```typescript
// ç»¼åˆè¿›åº¦è®¡ç®—
const calculateProgress = (state) => {
  const {
    compressProgress,   // å‹ç¼©è¿›åº¦ 0-30%
    uploadProgress,     // ä¸Šä¼ è¿›åº¦ 30-100%
  } = state;
  
  if (compressProgress < 100) {
    return compressProgress * 0.3;
  }
  
  return 30 + uploadProgress * 0.7;
};
```

## ğŸ’¡ é¢è¯•è¦ç‚¹

### 1. ä¸ºä»€ä¹ˆéœ€è¦åˆ†å—ä¸Šä¼ ï¼Ÿ
- **å¯é æ€§**ï¼šå¤§æ–‡ä»¶ä¸€æ¬¡æ€§ä¸Šä¼ å®¹æ˜“å¤±è´¥
- **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒä¸­æ–­åç»§ç»­ä¸Šä¼ 
- **å¹¶å‘æ§åˆ¶**ï¼šå¯ä»¥å¹¶è¡Œä¸Šä¼ å¤šä¸ªå—
- **ç”¨æˆ·ä½“éªŒ**ï¼šå®æ—¶æ˜¾ç¤ºè¿›åº¦

### 2. å‹ç¼© + åˆ†å—çš„ä¼˜åŠ¿
- **èŠ‚çœæµé‡**ï¼šå‹ç¼©ç‡ 70%+
- **æå‡é€Ÿåº¦**ï¼šä¼ è¾“é‡å‡å°‘
- **æé«˜æˆåŠŸç‡**ï¼šåˆ†å—ä¿è¯å¯é æ€§
- **æ›´å¥½ä½“éªŒ**ï¼šè¿›åº¦å¯è§†åŒ–

### 3. å¦‚ä½•å®ç°æ–­ç‚¹ç»­ä¼ ï¼Ÿ
1. **ç”Ÿæˆå”¯ä¸€ ID**ï¼šuploadId
2. **è®°å½•è¿›åº¦**ï¼šä¿å­˜å·²ä¸Šä¼ çš„å—
3. **æ£€æŸ¥çŠ¶æ€**ï¼šæ¢å¤æ—¶æŸ¥è¯¢æœåŠ¡ç«¯
4. **ç»§ç»­ä¸Šä¼ **ï¼šåªä¼ æœªå®Œæˆçš„å—

### 4. å¤§æ–‡æœ¬æ¸²æŸ“ä¼˜åŒ–
- **è™šæ‹ŸåŒ–**ï¼šåªæ¸²æŸ“å¯è§éƒ¨åˆ†
- **æ‡’åŠ è½½**ï¼šæŒ‰éœ€åŠ è½½å†…å®¹
- **å†…å®¹æŠ˜å **ï¼šé•¿æ–‡æœ¬è‡ªåŠ¨æŠ˜å 
- **åˆ†é¡µæ˜¾ç¤º**ï¼šè¶…é•¿å†…å®¹åˆ†é¡µ

### 5. IndexedDB vs LocalStorage
| ç‰¹æ€§ | IndexedDB | LocalStorage |
|------|-----------|--------------|
| å®¹é‡ | å‡ GB | 5-10MB |
| å¼‚æ­¥ | âœ… | âŒ |
| ç±»å‹ | ä»»æ„ç±»å‹ | åªæ”¯æŒå­—ç¬¦ä¸² |
| äº‹åŠ¡ | âœ… | âŒ |
| é€‚ç”¨ | å¤§æ•°æ® | å°é…ç½® |

## ğŸ”— ç›¸å…³æ¨¡å—

- **03-Streaming**ï¼šæµå¼ä¼ è¾“å¤§æ–‡æœ¬
- **06-Performance-Optimization**ï¼šæ¸²æŸ“æ€§èƒ½ä¼˜åŒ–
- **08-Data-Management**ï¼šIndexedDB ä½¿ç”¨

## ğŸ“Š å®ç°æ•ˆæœ

### æ€§èƒ½æå‡
- âœ… **ä¸Šä¼ æˆåŠŸç‡**ï¼šä» 60% æå‡åˆ° 99%
- âœ… **ä¼ è¾“é€Ÿåº¦**ï¼šèŠ‚çœ 70% æµé‡
- âœ… **æ¸²æŸ“æ€§èƒ½**ï¼š10,000+ æ¶ˆæ¯æ— å¡é¡¿
- âœ… **å†…å­˜å ç”¨**ï¼šå‡å°‘ 60%

### ç”¨æˆ·ä½“éªŒ
- âœ… æ”¯æŒ 100MB æ–‡æœ¬ä¸Šä¼ 
- âœ… å®æ—¶è¿›åº¦æ˜¾ç¤º
- âœ… æ–­ç‚¹ç»­ä¼ 
- âœ… æ— æ„ŸçŸ¥çš„æ€§èƒ½ä¼˜åŒ–

---

**å»ºè®®é˜…è¯»é¡ºåºï¼š**
1. `COMPLETE_LARGE_TEXT_SOLUTION.md` - å®Œæ•´æ–¹æ¡ˆ
2. `PROGRESSIVE_UPLOAD_STRATEGY.md` - ä¸Šä¼ ç­–ç•¥
3. `COMPRESSION_VS_CHUNKING_ANALYSIS.md` - æŠ€æœ¯é€‰å‹
4. `PROGRESSIVE_MESSAGE_LOADING.md` - æ¸²æŸ“ä¼˜åŒ–

