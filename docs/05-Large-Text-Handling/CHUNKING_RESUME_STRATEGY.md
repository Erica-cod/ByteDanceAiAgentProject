# Chunking æ–­ç‚¹ç»­ä¼ ç­–ç•¥è¯¦è§£

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

Chunking å¤„ç†æœ‰ 4 ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µçš„æ–­ç‚¹ç»­ä¼ ç­–ç•¥ä¸åŒï¼š

| é˜¶æ®µ | è€—æ—¶ | æ˜¯å¦è°ƒç”¨æ¨¡å‹ | SSEæ–­è¿é£é™© | ç»­ä¼ ç­–ç•¥ |
|------|------|-------------|------------|---------|
| **1. Split** | <1ç§’ | âŒ | æä½ | æ— éœ€ç»­ä¼  |
| **2. Map** | 150ç§’ (30 chunks Ã— 5ç§’) | âœ… | **é«˜** | **éœ€è¦ç»­ä¼ ** |
| **3. Reduce** | <1ç§’ | âŒ | æä½ | æ— éœ€ç»­ä¼  |
| **4. Final** | 30-60ç§’ | âœ… | **ä¸­** | **éœ€è¦ç»­ä¼ ** |

## ğŸ”¥ å…³é”®æ´å¯Ÿ

### Map é˜¶æ®µ vs Final é˜¶æ®µçš„åŒºåˆ«

```typescript
// Map é˜¶æ®µï¼šæ¯ä¸ª chunk å¤„ç†å®Œæ•´åæ‰ç»§ç»­ä¸‹ä¸€ä¸ª
for (let i = 0; i < chunks.length; i++) {
  const chunkData = await processChunk(chunk, i, totalChunks);
  // âœ… processChunk å†…éƒ¨å®Œå…¨æ¶ˆè´¹æµï¼Œè¿”å›å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®
  // âœ… æ¯ä¸ª chunk æ˜¯ç‹¬ç«‹çš„ï¼Œä¸­æ–­åå¯ä»¥ä»ä¸‹ä¸€ä¸ª chunk ç»§ç»­
  extractedDataList.push(chunkData);
}

// Final é˜¶æ®µï¼šæµå¼è¾“å‡ºç»™ç”¨æˆ·
for await (const chunk of stream) {
  if (sseWriter.isClosed()) break;  // âš ï¸ ä¸­æ–­æ—¶åªè¾“å‡ºäº†ä¸€åŠ
  
  accumulatedText += content;
  await sseWriter.sendEvent({ content: mainContent });
  // âš ï¸ å¦‚æœè¿™é‡Œæ–­è¿ï¼Œå·²è¾“å‡ºçš„å†…å®¹æ€ä¹ˆåŠï¼Ÿ
}
```

**åŒºåˆ«**ï¼š
- **Map é˜¶æ®µ**ï¼šæ¯ä¸ª chunk å¤„ç†å®Œæ•´ï¼Œæœ‰æ˜ç¡®çš„"è¿›åº¦å•ä½"
- **Final é˜¶æ®µ**ï¼šæµå¼è¾“å‡ºï¼Œæ²¡æœ‰æ˜ç¡®çš„"è¿›åº¦å•ä½"ï¼Œéšæ—¶å¯èƒ½ä¸­æ–­

## âœ… å®Œæ•´è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä¿å®ˆç­–ç•¥ï¼ˆæ¨èï¼‰ - ä¿å­˜ Map ç»“æœï¼ŒFinal é‡æ–°ç”Ÿæˆ

#### æ ¸å¿ƒæ€è·¯

```
Map é˜¶æ®µæ–­è¿ â†’ ä¿å­˜è¿›åº¦ â†’ é‡è¿åç»§ç»­å‰©ä½™ chunk
                â†“
            æ‰€æœ‰ chunk å¤„ç†å®Œ
                â†“
            è¿›å…¥ Final é˜¶æ®µ
                â†“
Final é˜¶æ®µæ–­è¿ â†’ ä¸ä¿å­˜ Final å†…å®¹ â†’ é‡è¿åé‡æ–°ç”Ÿæˆ
                â†“
            (å› ä¸º Final åªéœ€ 30-60 ç§’ï¼Œå¯ä»¥æ¥å—)
```

#### ä¼˜ç‚¹
- âœ… å®ç°ç®€å•
- âœ… Map é˜¶æ®µï¼ˆæœ€è€—æ—¶ï¼‰å¯ä»¥ç»­ä¼ 
- âœ… Final é‡æ–°ç”Ÿæˆå¯èƒ½æ›´è¿è´¯ï¼ˆé¿å…æ‹¼æ¥ç—•è¿¹ï¼‰

#### ç¼ºç‚¹
- âš ï¸ Final é˜¶æ®µæ–­è¿éœ€é‡æ–°ç”Ÿæˆï¼ˆä½†åªéœ€ 30-60 ç§’ï¼‰

#### å®ç°ä»£ç 

```typescript
// api/services/chunkingPlanReviewService.ts

export async function handleChunkingPlanReview(
  message: string,
  userId: string,
  conversationId: string,
  clientAssistantMessageId: string | undefined,
  modelType: 'local' | 'volcano',
  sseWriter: SSEStreamWriter,
  options: ChunkingOptions = {},
  resumeFromChunk?: number  // âœ… æ–­ç‚¹ç»­ä¼ å‚æ•°
): Promise<void> {
  const chunkingId = `chunking:${conversationId}:${clientAssistantMessageId || Date.now()}`;
  
  try {
    // ==================== 1. Split é˜¶æ®µ ====================
    const chunks = splitTextIntoChunks(message, {
      maxChunks: options.maxChunks || 30,
    });
    
    // ==================== 2. Map é˜¶æ®µ (æ”¯æŒæ–­ç‚¹ç»­ä¼ ) ====================
    let startIndex = 0;
    let extractedDataList: ExtractedData[] = [];
    
    // âœ… å°è¯•ä» Redis æ¢å¤è¿›åº¦
    if (resumeFromChunk !== undefined) {
      const savedProgress = await redis.get(`${chunkingId}:map_progress`);
      if (savedProgress) {
        const progress = JSON.parse(savedProgress);
        extractedDataList = progress.extractedDataList || [];
        startIndex = resumeFromChunk;
        
        console.log(`âœ… [Chunking] ä» Map é˜¶æ®µç¬¬ ${startIndex} ä¸ª chunk æ¢å¤`);
        
        await sseWriter.sendEvent({
          type: 'chunking_resume',
          stage: 'map',
          resumedFromChunk: startIndex,
          totalChunks: chunks.length,
        });
      }
    }
    
    await sseWriter.sendEvent({
      type: 'chunking_init',
      totalChunks: chunks.length,
      startFromChunk: startIndex,
    });
    
    // å¤„ç†æ¯ä¸ª chunk
    for (let i = startIndex; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      // âš ï¸ æ£€æŸ¥ SSE æ˜¯å¦å…³é—­
      if (sseWriter.isClosed()) {
        console.log(`âš ï¸ [Chunking] SSE æ–­è¿ (Map é˜¶æ®µç¬¬ ${i} ä¸ª chunk)ï¼Œä¿å­˜è¿›åº¦`);
        
        // âœ… ä¿å­˜ Map é˜¶æ®µè¿›åº¦
        await redis.set(
          `${chunkingId}:map_progress`,
          JSON.stringify({
            stage: 'map',
            lastCompletedChunk: i - 1,
            extractedDataList,
          }),
          'EX',
          3600  // 1 å°æ—¶è¿‡æœŸ
        );
        
        return;  // é€€å‡ºï¼Œç­‰å¾…é‡è¿
      }
      
      await sseWriter.sendEvent({
        type: 'chunking_progress',
        stage: 'map',
        chunkIndex: i,
        totalChunks: chunks.length,
      });
      
      console.log(`ğŸ” [Chunking] åˆ†æç¬¬ ${i + 1}/${chunks.length} æ®µ...`);
      
      // è°ƒç”¨æ¨¡å‹åˆ†æ (å¸¦é‡è¯•)
      const chunkData = await processChunkWithRetry(chunk, i, chunks.length, 3);
      extractedDataList.push(chunkData);
      
      await sseWriter.sendEvent({
        type: 'chunking_chunk',
        chunkIndex: i,
        chunkSummary: chunkData.goals.join('; '),
      });
      
      // âœ… æ¯ 5 ä¸ª chunk ä¿å­˜ä¸€æ¬¡è¿›åº¦
      if ((i + 1) % 5 === 0) {
        await redis.set(
          `${chunkingId}:map_progress`,
          JSON.stringify({
            stage: 'map',
            lastCompletedChunk: i,
            extractedDataList,
          }),
          'EX',
          3600
        );
        console.log(`ğŸ’¾ [Chunking] å·²ä¿å­˜ Map è¿›åº¦ (${i + 1}/${chunks.length})`);
      }
    }
    
    console.log('âœ… [Chunking] Map é˜¶æ®µå®Œæˆ');
    
    // ==================== 3. Reduce é˜¶æ®µ ====================
    await sseWriter.sendEvent({
      type: 'chunking_progress',
      stage: 'reduce',
    });
    
    console.log('ğŸ”„ [Chunking] åˆå¹¶åˆ†æç»“æœ...');
    const mergedData = mergeExtractedData(extractedDataList);
    
    // âœ… ä¿å­˜åˆå¹¶åçš„æ•°æ®ï¼ˆä¸º Final é˜¶æ®µå‡†å¤‡ï¼‰
    await redis.set(
      `${chunkingId}:merged_data`,
      JSON.stringify(mergedData),
      'EX',
      3600
    );
    
    // ==================== 4. Final é˜¶æ®µ (ä¸æ”¯æŒç»­ä¼ ï¼Œé‡æ–°ç”Ÿæˆ) ====================
    await sseWriter.sendEvent({
      type: 'chunking_progress',
      stage: 'final',
    });
    
    console.log('ğŸ“ [Chunking] ç”Ÿæˆæœ€ç»ˆè¯„å®¡æŠ¥å‘Š...');
    
    const finalPrompt = buildReducePrompt(mergedData, message, chunks.length);
    const messages: ChatMessage[] = [
      { role: 'user', content: finalPrompt }
    ];
    
    const stream = await callVolcengineModel(messages);
    
    // æµå¼è¾“å‡ºæœ€ç»ˆç»“æœ
    let buffer = '';
    let accumulatedText = '';
    
    for await (const chunk of stream) {
      // âš ï¸ æ£€æŸ¥ SSE æ˜¯å¦å…³é—­
      if (sseWriter.isClosed()) {
        console.log('âš ï¸ [Chunking] SSE æ–­è¿ (Final é˜¶æ®µ)');
        
        // âŒ ä¸ä¿å­˜ Final çš„éƒ¨åˆ†å†…å®¹
        // âŒ å› ä¸ºéƒ¨åˆ†å†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼Œé‡è¿åé‡æ–°ç”Ÿæˆæ›´å¥½
        
        // âœ… ä¿å­˜å·²ç”Ÿæˆçš„å†…å®¹åˆ°æ•°æ®åº“ï¼ˆä½œä¸ºä¸å®Œæ•´çš„å›ç­”ï¼‰
        if (accumulatedText) {
          const { thinking, content } = extractThinkingAndContent(accumulatedText);
          await MessageService.addMessage(
            conversationId,
            userId,
            'assistant',
            content || accumulatedText,
            clientAssistantMessageId,
            thinking,
            modelType
          );
          console.log('ğŸ’¾ [Chunking] å·²ä¿å­˜ä¸å®Œæ•´çš„ Final å†…å®¹åˆ°æ•°æ®åº“');
        }
        
        return;  // é€€å‡ºï¼Œç­‰å¾…é‡è¿ï¼ˆé‡è¿åä¼šé‡æ–°ç”Ÿæˆ Finalï¼‰
      }
      
      const chunkStr = chunk.toString();
      buffer += chunkStr;
      
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';
      
      for (const line of lines) {
        if (line.trim()) {
          const content = volcengineService.parseStreamLine(line);
          
          if (content) {
            accumulatedText += content;
            const { thinking, content: mainContent } = extractThinkingAndContent(accumulatedText);
            
            await sseWriter.sendEvent({
              content: mainContent,
              thinking: thinking || undefined,
            });
          }
          
          if (line.includes('[DONE]')) {
            console.log('âœ… [Chunking] æœ€ç»ˆè¯„å®¡å®Œæˆ');
            break;
          }
        }
      }
    }
    
    // âœ… Final é˜¶æ®µå®Œæˆï¼Œä¿å­˜åˆ°æ•°æ®åº“
    if (accumulatedText) {
      const { thinking, content } = extractThinkingAndContent(accumulatedText);
      await MessageService.addMessage(
        conversationId,
        userId,
        'assistant',
        content || accumulatedText,
        clientAssistantMessageId,
        thinking,
        modelType
      );
      await ConversationService.incrementMessageCount(conversationId, userId);
      console.log('âœ… [Chunking] æ¶ˆæ¯å·²ä¿å­˜åˆ°æ•°æ®åº“');
    }
    
    // âœ… å®Œæˆåæ¸…ç† Redis è¿›åº¦
    await redis.del(`${chunkingId}:map_progress`);
    await redis.del(`${chunkingId}:merged_data`);
    
  } catch (error: any) {
    console.error('âŒ [Chunking] å¤„ç†å¤±è´¥:', error);
    throw error;
  }
}

/**
 * âœ… å¸¦é‡è¯•çš„ chunk å¤„ç†
 */
async function processChunkWithRetry(
  chunk: TextChunk,
  chunkIndex: number,
  totalChunks: number,
  maxRetries: number = 3
): Promise<ExtractedData> {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await processChunk(chunk, chunkIndex, totalChunks);
    } catch (error) {
      console.warn(`âš ï¸ [Chunking] Chunk ${chunkIndex} å¤„ç†å¤±è´¥ (å°è¯• ${attempt + 1}/${maxRetries})`, error);
      
      if (attempt === maxRetries - 1) {
        // æœ€åä¸€æ¬¡å¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®
        console.error(`âŒ [Chunking] Chunk ${chunkIndex} æœ€ç»ˆå¤±è´¥ï¼Œè¿”å›ç©ºæ•°æ®`);
        return {
          goals: [],
          milestones: [],
          tasks: [],
          metrics: [],
          risks: [],
          unknowns: [],
        };
      }
      
      // æŒ‡æ•°é€€é¿
      await new Promise(resolve => setTimeout(resolve, 1000 * Math.pow(2, attempt)));
    }
  }
  
  // TypeScript ç±»å‹æ£€æŸ¥
  return {
    goals: [],
    milestones: [],
    tasks: [],
    metrics: [],
    risks: [],
    unknowns: [],
  };
}
```

#### å‰ç«¯ä¿®æ”¹

```typescript
// src/hooks/data/useSSEStream.ts

export function useSSEStream(options: UseSSEStreamOptions = {}) {
  // âœ… è®°å½•å½“å‰ chunking çŠ¶æ€
  const [chunkingState, setChunkingState] = useState<{
    stage: 'map' | 'reduce' | 'final' | null;
    lastCompletedChunk: number | null;
  }>({
    stage: null,
    lastCompletedChunk: null,
  });
  
  const sendMessage = async (messageText: string, /* ... */) => {
    // ...
    
    const runStreamOnce = async (): Promise<{ completed: boolean; aborted: boolean }> => {
      // âœ… æ„å»ºè¯·æ±‚ä½“
      const requestBody = {
        message: messageText,
        // ...
        // âœ… å¦‚æœåœ¨ Map é˜¶æ®µæ–­è¿ï¼Œä¼ é€’ç»­ä¼ å‚æ•°
        ...(chunkingState.stage === 'map' && chunkingState.lastCompletedChunk !== null ? {
          resumeFromChunk: chunkingState.lastCompletedChunk + 1
        } : {}),
      };
      
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody),
        signal,
      });
      
      // ...è§£æ SSE æµ
      
      const eventData = JSON.parse(line.slice(5).trim());
      
      // âœ… è·Ÿè¸ª chunking è¿›åº¦
      if (eventData.type === 'chunking_progress') {
        setChunkingState({
          stage: eventData.stage,
          lastCompletedChunk: eventData.chunkIndex ?? null,
        });
      }
      
      if (eventData.type === 'chunking_chunk') {
        setChunkingState(prev => ({
          ...prev,
          lastCompletedChunk: eventData.chunkIndex,
        }));
      }
      
      // âœ… æ˜¾ç¤ºç»­ä¼ æç¤º
      if (eventData.type === 'chunking_resume') {
        updateMessage(assistantMessageId, {
          thinking: `ä»ç¬¬ ${eventData.resumedFromChunk + 1} æ®µç»§ç»­å¤„ç†...`,
        });
      }
      
      // âœ… å®Œæˆåé‡ç½®
      if (isDone) {
        setChunkingState({ stage: null, lastCompletedChunk: null });
      }
      
      // ...
    };
    
    // æ–­çº¿é‡è¿
    let attempt = 0;
    while (true) {
      const result = await runStreamOnce();
      
      if (result.completed) break;
      
      if (attempt >= MAX_RECONNECT_ATTEMPTS) {
        throw new Error('SSE è¿æ¥ä¸­æ–­ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°');
      }
      
      const waitMs = computeBackoff(attempt);
      
      // âœ… æ ¹æ®é˜¶æ®µæ˜¾ç¤ºä¸åŒæç¤º
      if (chunkingState.stage === 'map') {
        updateMessage(assistantMessageId, {
          thinking: `è¿æ¥ä¸­æ–­ï¼Œæ­£åœ¨é‡è¿...(å°†ä»ç¬¬ ${(chunkingState.lastCompletedChunk || 0) + 1} æ®µç»§ç»­)`,
        });
      } else if (chunkingState.stage === 'final') {
        updateMessage(assistantMessageId, {
          thinking: `è¿æ¥ä¸­æ–­ï¼Œæ­£åœ¨é‡è¿...(å°†é‡æ–°ç”ŸæˆæŠ¥å‘Š)`,
        });
      } else {
        updateMessage(assistantMessageId, {
          thinking: 'è¿æ¥ä¸­æ–­ï¼Œæ­£åœ¨å°è¯•é‡è¿...',
        });
      }
      
      await sleep(waitMs);
      attempt += 1;
    }
  };
  
  // ...
}
```

---

### æ–¹æ¡ˆ 2: æ¿€è¿›ç­–ç•¥ - ä¿å­˜ Final å†…å®¹ï¼Œç»­ä¼ æ‹¼æ¥

#### æ ¸å¿ƒæ€è·¯

Final é˜¶æ®µä¹Ÿä¿å­˜è¿›åº¦ï¼Œé‡è¿åç»­ä¼ ï¼ˆç±»ä¼¼ ChatGPT çš„"ç»§ç»­"åŠŸèƒ½ï¼‰ã€‚

```
Final é˜¶æ®µè¾“å‡ºåˆ°ä¸€åŠ â†’ ä¿å­˜å·²è¾“å‡ºå†…å®¹
            â†“
        SSE æ–­è¿
            â†“
        é‡è¿åå‘é€ç‰¹æ®Š prompt: "ç»§ç»­ä¸Šè¿°æŠ¥å‘Šï¼Œä»ã€æœ€åä¸€å¥ã€‘ç»§ç»­..."
            â†“
        æ¨¡å‹ç»§ç»­ç”ŸæˆååŠéƒ¨åˆ†
            â†“
        æ‹¼æ¥å‰åå†…å®¹
```

#### ä¼˜ç‚¹
- âœ… èŠ‚çœ Final é˜¶æ®µæ—¶é—´ï¼ˆç»­ä¼ è€Œä¸æ˜¯é‡æ–°ç”Ÿæˆï¼‰
- âœ… ç”¨æˆ·ä½“éªŒæ›´å¥½ï¼ˆæ— æ„ŸçŸ¥ç»­ä¼ ï¼‰

#### ç¼ºç‚¹
- âš ï¸ å®ç°å¤æ‚
- âš ï¸ æ‹¼æ¥å¯èƒ½æœ‰ä¸è¿è´¯ï¼ˆæ¨¡å‹ä¸çŸ¥é“å‰é¢å†…å®¹çš„ä¸Šä¸‹æ–‡ï¼‰
- âš ï¸ éœ€è¦è®¾è®¡"ç»­ä¼  prompt"

#### å®ç°è¦ç‚¹

```typescript
// Final é˜¶æ®µæ–­è¿æ—¶ä¿å­˜å†…å®¹
if (sseWriter.isClosed()) {
  // âœ… ä¿å­˜ Final çš„éƒ¨åˆ†å†…å®¹
  await redis.set(
    `${chunkingId}:final_partial`,
    JSON.stringify({
      stage: 'final',
      partialContent: accumulatedText,
      mergedData,  // ä¿å­˜åˆå¹¶æ•°æ®ï¼Œä¾›ç»­ä¼ ä½¿ç”¨
    }),
    'EX',
    3600
  );
  return;
}

// é‡è¿åæ£€æŸ¥æ˜¯å¦åœ¨ Final é˜¶æ®µ
const finalPartial = await redis.get(`${chunkingId}:final_partial`);
if (finalPartial) {
  const { partialContent, mergedData } = JSON.parse(finalPartial);
  
  // âœ… å…ˆå‘é€å·²æœ‰å†…å®¹ç»™å‰ç«¯
  await sseWriter.sendEvent({
    content: partialContent,
    thinking: 'æ­£åœ¨ç»§ç»­ç”ŸæˆæŠ¥å‘Š...',
  });
  
  // âœ… æ„å»ºç»­ä¼  prompt
  const resumePrompt = buildResumeFinalPrompt(mergedData, partialContent);
  
  // âœ… è°ƒç”¨æ¨¡å‹ç»§ç»­ç”Ÿæˆ
  const stream = await callVolcengineModel([
    { role: 'user', content: resumePrompt }
  ]);
  
  // âœ… æ‹¼æ¥æ–°å†…å®¹
  let newContent = '';
  for await (const chunk of stream) {
    // ...
    newContent += content;
    
    await sseWriter.sendEvent({
      content: partialContent + newContent,  // æ‹¼æ¥
    });
  }
}
```

#### ç»­ä¼  Prompt è®¾è®¡

```typescript
function buildResumeFinalPrompt(mergedData: ExtractedData, partialContent: string): string {
  // æå–æœ€åä¸€å¥è¯
  const lastSentence = partialContent.split('\n').filter(s => s.trim()).pop() || '';
  
  return `
ä½ ä¹‹å‰æ­£åœ¨ç”Ÿæˆä¸€ä»½é¡¹ç›®è®¡åˆ’è¯„å®¡æŠ¥å‘Šï¼Œä½†ç”±äºç½‘ç»œä¸­æ–­ï¼ŒæŠ¥å‘Šç”Ÿæˆåˆ°ä¸€åŠã€‚

ä»¥ä¸‹æ˜¯ä½ å·²ç»ç”Ÿæˆçš„å†…å®¹ï¼ˆæœ€åä¸€å¥æ˜¯ï¼š"${lastSentence}"ï¼‰ï¼š

---
${partialContent}
---

è¯·**ç›´æ¥ç»§ç»­**ä¸Šè¿°æŠ¥å‘Šï¼Œä»æœ€åä¸€å¥ä¹‹åç»§ç»­å†™ï¼Œä¸è¦é‡å¤å·²æœ‰å†…å®¹ï¼Œä¿æŒé£æ ¼ä¸€è‡´ã€‚

åŸºç¡€æ•°æ®ï¼š
${JSON.stringify(mergedData, null, 2)}

ç»§ç»­ç”Ÿæˆï¼š
`.trim();
}
```

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | æ–¹æ¡ˆ 1 (ä¿å®ˆ) | æ–¹æ¡ˆ 2 (æ¿€è¿›) |
|------|--------------|--------------|
| **å®ç°å¤æ‚åº¦** | â­â­ (ç®€å•) | â­â­â­â­ (å¤æ‚) |
| **Map é˜¶æ®µç»­ä¼ ** | âœ… æ”¯æŒ | âœ… æ”¯æŒ |
| **Final é˜¶æ®µç»­ä¼ ** | âŒ é‡æ–°ç”Ÿæˆ (30-60ç§’) | âœ… æ”¯æŒ (èŠ‚çœæ—¶é—´) |
| **å†…å®¹è¿è´¯æ€§** | âœ… å®Œæ•´ç”Ÿæˆï¼Œæ›´è¿è´¯ | âš ï¸ æ‹¼æ¥å¯èƒ½æœ‰ç—•è¿¹ |
| **ç”¨æˆ·ä½“éªŒ** | âœ… å¥½ | âœ… å¾ˆå¥½ |
| **ç»´æŠ¤æˆæœ¬** | âœ… ä½ | âš ï¸ é«˜ (éœ€è¦è°ƒè¯•ç»­ä¼ æ•ˆæœ) |

---

## ğŸ¯ æ¨èç­–ç•¥

### ç«‹å³å®æ–½ï¼šæ–¹æ¡ˆ 1 (ä¿å®ˆç­–ç•¥)

**åŸå› **ï¼š
1. **Map é˜¶æ®µæ˜¯å¤§å¤´**ï¼š150 ç§’ vs Final 30-60 ç§’
2. **å®ç°ç®€å•**ï¼š1-2 å¤©å³å¯å®Œæˆ
3. **æ•ˆæœæ˜æ˜¾**ï¼šèŠ‚çœ 80%+ çš„é‡å¤æ—¶é—´
4. **é£é™©ä½**ï¼šé€»è¾‘æ¸…æ™°ï¼Œæ˜“äºæµ‹è¯•

### æœªæ¥ä¼˜åŒ–ï¼šæ–¹æ¡ˆ 2 (æ¿€è¿›ç­–ç•¥)

**æ¡ä»¶**ï¼š
- æ–¹æ¡ˆ 1 ç¨³å®šè¿è¡Œå
- ç”¨æˆ·åé¦ˆ Final é˜¶æ®µé‡è¿é¢‘ç¹
- æœ‰æ—¶é—´æŠ•å…¥è°ƒä¼˜ç»­ä¼  prompt

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### æµ‹è¯•åœºæ™¯ 1: Map é˜¶æ®µæ–­è¿

```javascript
// test/test-map-resume.js

async function testMapResume() {
  const longText = generateLongPlanText();
  
  // ç¬¬ä¸€æ¬¡è¯·æ±‚ (5ç§’åä¸»åŠ¨æ–­å¼€)
  const controller1 = new AbortController();
  setTimeout(() => controller1.abort(), 5000);
  
  let lastChunk = 0;
  
  try {
    const response1 = await fetch('http://localhost:8080/api/chat', {
      method: 'POST',
      body: JSON.stringify({
        message: longText,
        mode: 'single',
        longTextMode: 'plan_review',
        clientAssistantMessageId: 'test-msg-123',
      }),
      signal: controller1.signal,
    });
    
    // ç›‘å¬è¿›åº¦
    for await (const chunk of response1.body) {
      const data = parseSSE(chunk);
      if (data.type === 'chunking_chunk') {
        lastChunk = data.chunkIndex;
      }
    }
  } catch (error) {
    console.log(`âš ï¸ ä¸­æ–­ï¼Œå·²å®Œæˆ ${lastChunk + 1} ä¸ª chunk`);
  }
  
  // ç­‰å¾… 2 ç§’
  await sleep(2000);
  
  // ç¬¬äºŒæ¬¡è¯·æ±‚ (æ–­ç‚¹ç»­ä¼ )
  const response2 = await fetch('http://localhost:8080/api/chat', {
    method: 'POST',
    body: JSON.stringify({
      message: longText,
      mode: 'single',
      longTextMode: 'plan_review',
      clientAssistantMessageId: 'test-msg-123',
      resumeFromChunk: lastChunk + 1,  // âœ… ç»­ä¼ 
    }),
  });
  
  // éªŒè¯æ˜¯å¦ç»­ä¼ æˆåŠŸ
  for await (const chunk of response2.body) {
    const data = parseSSE(chunk);
    if (data.type === 'chunking_resume') {
      console.log(`âœ… æˆåŠŸç»­ä¼ ! ä»ç¬¬ ${data.resumedFromChunk} ä¸ª chunk ç»§ç»­`);
      break;
    }
  }
}
```

### æµ‹è¯•åœºæ™¯ 2: Final é˜¶æ®µæ–­è¿

```javascript
async function testFinalInterrupt() {
  const longText = generateLongPlanText();
  
  // ç¬¬ä¸€æ¬¡è¯·æ±‚ (ç­‰å¾…è¿›å…¥ Final é˜¶æ®µåæ–­å¼€)
  const controller1 = new AbortController();
  
  let inFinalStage = false;
  
  const response1 = await fetch('http://localhost:8080/api/chat', {
    method: 'POST',
    body: JSON.stringify({
      message: longText,
      mode: 'single',
      longTextMode: 'plan_review',
      clientAssistantMessageId: 'test-msg-456',
    }),
    signal: controller1.signal,
  });
  
  try {
    for await (const chunk of response1.body) {
      const data = parseSSE(chunk);
      
      // æ£€æµ‹åˆ°è¿›å…¥ Final é˜¶æ®µ
      if (data.type === 'chunking_progress' && data.stage === 'final') {
        inFinalStage = true;
      }
      
      // Final é˜¶æ®µè¾“å‡º 2 ç§’åæ–­å¼€
      if (inFinalStage && data.content) {
        setTimeout(() => controller1.abort(), 2000);
      }
    }
  } catch (error) {
    console.log('âš ï¸ Final é˜¶æ®µä¸­æ–­');
  }
  
  // é‡è¿ (æ–¹æ¡ˆ 1: ä¼šé‡æ–°ç”Ÿæˆ Final)
  console.log('ğŸ”„ é‡è¿ä¸­...');
  
  const response2 = await fetch('http://localhost:8080/api/chat', {
    method: 'POST',
    body: JSON.stringify({
      message: longText,
      mode: 'single',
      longTextMode: 'plan_review',
      clientAssistantMessageId: 'test-msg-456',
      // âœ… å› ä¸º Map é˜¶æ®µå·²å®Œæˆï¼Œä¼šç›´æ¥è¿›å…¥ Final
    }),
  });
  
  for await (const chunk of response2.body) {
    const data = parseSSE(chunk);
    if (data.type === 'chunking_progress' && data.stage === 'final') {
      console.log('âœ… é‡æ–°ç”Ÿæˆ Final æŠ¥å‘Š');
    }
  }
}
```

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒç­”æ¡ˆ

**ä½ çš„æ‹…å¿ƒï¼šæ¨¡å‹åœ¨éƒ¨åˆ†åˆ†ç‰‡æ¥æ”¶åˆ°çš„æ—¶å€™ï¼Œå°±å·²ç»å¼€å§‹åˆ†æè¾“å‡ºäº†**

**å®é™…æƒ…å†µ**ï¼š
- **Map é˜¶æ®µ**ï¼šæ¯ä¸ª chunk **å®Œæ•´å¤„ç†**åæ‰ç»§ç»­ï¼Œå¯ä»¥ä¿å­˜è¿›åº¦
- **Final é˜¶æ®µ**ï¼šæ˜¯**æµå¼è¾“å‡º**ï¼Œç¡®å®å¯èƒ½ä¸­æ–­

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. âœ… **Map é˜¶æ®µ**ï¼šä¿å­˜è¿›åº¦ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼  (èŠ‚çœ 150 ç§’)
2. âš ï¸ **Final é˜¶æ®µ**ï¼šä¸ä¿å­˜è¿›åº¦ï¼Œé‡è¿åé‡æ–°ç”Ÿæˆ (åªéœ€ 30-60 ç§’)

### å…³é”®ç‚¹

- âœ… **80/20 åŸåˆ™**ï¼šMap å  80% æ—¶é—´ï¼Œä¼˜å…ˆä¼˜åŒ–å®ƒ
- âœ… **å¯æ¥å—çš„ä»£ä»·**ï¼šFinal é‡æ–°ç”Ÿæˆ 30 ç§’ï¼Œç”¨æˆ·å¯ä»¥æ¥å—
- âœ… **å®ç°ç®€å•**ï¼šä¿å®ˆç­–ç•¥ 1-2 å¤©å¯å®Œæˆ

---

**ä½œè€…**: AI Assistant  
**æ—¥æœŸ**: 2024-12-30  
**ç‰ˆæœ¬**: 1.0.0

