### P1 业务亮点：多工具、工具流编排

我的项目实现了工具调用，并使用 Tavily 封装了联网搜索工具；同时提供计划工具、时间工具，支持“工具流”的线性多步调用：一个用户请求，模型可以按需调用多个工具。

- **业务场景**：例如“你搜索网络，帮我制定一个新手小白学习乒乓球的 3 个月计划，下个星期开始”。
- **场景分析**
  - 用户说“下个星期开始”隐含了时间信息。早期接入本地/远程模型时，模型对“现在时间”理解不可靠（常用模型发布日期当作现在），导致计划日期错乱，所以需要时间工具提供真实当前时间。
  - “3 个月计划”天然有 CRUD 需求：用户可能反复修改开始时间/周期等；且上下文变长会被窗口截断，因此需要计划工具做持久化与可编辑。

我们的工具系统经历了两次重要迭代：

#### V1：Prompt + LangChain.js
最初采用 LangChain 的 `AgentExecutor`，主要基于 Prompt 解析：
- 在 Prompt 中描述工具与使用格式
- 使用 LangChain 的 OutputParser 解析模型返回
- 依靠 ReAct（Reasoning → Action → Observation）执行多步任务

遇到 4 个核心问题：
1. **模型幻觉/格式不稳定**：经常因为格式错误调用失败
   - 例如返回 `"<tool_call>search_web AI技术</tool_call>"`
   - 或返回“调用 search_ai 工具”（工具名都错了）
2. **多步执行不可靠**：有些模型只做第一步就停
   - 用户说“列计划 → 查详情 → 更新”，模型列出计划就结束
3. **Token 消耗高**：每次都要描述工具，平均 1200 tokens/次
4. **依赖偏重**：LangChain 打包后增加约 2.3MB

#### 决定重构的转折点
OpenAI 推出 Function Calling，让我们看到更可控的路径：
1. Function Calling 是结构化调用，模型返回 JSON，格式错误显著减少
2. ReAct 更偏探索式执行，我们需要“可控的多步编排”
3. 可以实现更轻量的方案，并加入限流、缓存、熔断等保护

#### V2：自定义编排 + Function Calling
我们重写了工具系统，核心改进：
1. **迁移到 Function Calling**
   - 工具定义变成 JSON Schema
   - 模型返回结构化数据
   - 参数自动验证，不会调用不存在的工具
2. **自定义工具编排器（约 300 行）**
   - 拓扑排序解析依赖关系
   - 支持变量引用：`${step1.data.field}`
   - 失败策略：`abort / continue / retry`
3. **插件式架构**
   - 每个工具独立插件，注册即用
   - 自动获得限流、缓存、熔断保护
4. **三层保护机制**
   - 限流：50 并发 + 100 次/分钟（滑动窗口）
   - 缓存：5 分钟 TTL，节省 80% API 调用
   - 熔断：连续失败 5 次自动熔断，避免雪崩

---

### P2 多 Agent 思考设计（待补充）
参考 GitHub 热门开源项目：[微舆 BettaFish](https://github.com/666ghj/BettaFish)。该项目将舆情分析拆分为多个专业化引擎（数据采集/媒体分析/论坛分析/深度洞察/报告生成），通过职责分离避免“单模块干所有事”的质量下降。

结合项目时间与成本约束，我将“方案制定”拆解为：**提案 → 质询 → 决策 → 总结**四个环节：
1. **Planner（规划师）**：建设者角色，专注“如何做”，输出结构化计划（阶段、任务、时间估算）。
2. **Critic（批评家）**：质询者角色，专注“哪里有问题”，提供与 Planner 互补视角，避免过度乐观。
3. **Reporter（报告员）**：输出者角色，智能提取共识与风险点，不是简单拼接。

同时设置讨论轮次硬上限，达到上限后强制总结，防止 token 过度消耗与用户等待过久。

---

### P3 用户友好体验
采用 SSE 实现对话流式输出；国际化使用 i18next；主题切换用 Zustand 管理；并使用 AbortController 支持用户中断生成。

#### 国际化与主题切换
- 国际化：i18next + 按模块管理翻译文件 + 语言检测与持久化
- 主题：Zustand 管理三种模式（浅色/深色/跟随系统）。双层状态：`theme` 存用户选择，`effectiveTheme` 存实际主题。

`matchMedia` 示例：

```ts
const mediaQuery = matchMedia('(prefers-color-scheme: dark)');

// 1) 立即检测系统主题
mediaQuery.matches; // true = 深色, false = 浅色

// 2) 监听系统主题变化
mediaQuery.addEventListener('change', (e) => {
  console.log(e.matches); // 系统主题改变时触发
});
```

#### 模式切换防闪烁（关键点）
1. 在恢复持久化状态时立即应用主题
2. CSS 过渡动画，避免瞬间切换（例如 `transition: background-color 0.2s ease`）
3. 初始化时机尽量靠前（例如在 `App.tsx` 最早的 `useEffect`）

---

### P4 服务端行为预测与防范
高并发 edge case：200–500 人同时使用多 Agent，且大量用户断线重连。

我们做了 4 个关键设计：
1. **指数退避重试**：`2^n` 指数增长 + 随机 jitter 避免惊群，重试间隔从 1 秒增长到 10 秒。
2. **服务端队列防惊群（两层队列）**
   - 第 1 层：用户请求队列。SSE 并发满时返回 429 + `Retry-After` + 队列位置 Token；客户端携带 Token 重试保持队列位置并展示排队位次。
   - 第 2 层：LLM 请求队列。优先级调度（Host > Planner > Critic > Reporter）+ 并发与 RPM 双限制，支持 500 用户同时访问不宕机。
3. **跨浏览器防刷重试**：Canvas 指纹 + GPU 等硬件特征做设备识别，SHA-256 匿名化后实现跨浏览器识别同一设备。
4. **隐私保护**：SHA-256 单向哈希、网站专属盐值、数据最小化、30 天自动删除，符合法律隐私要求。

#### 数据流（简版）
- 用户请求
  - 第 1 层：SSE 并发检查（200）
    - 有空位：立即处理
    - 无空位：入队 → 返回 429 + Token + Retry-After
  - 用户携带 Token 重试（按 Retry-After 延迟）
  - 保持队列位置 → 等待前面用户完成 → 获得空位
  - 第 2 层：LLM 请求队列（50 并发 + 500 RPM）
    - 按优先级排序
    - 检查并发和 RPM 限制
    - 逐个调用 LLM API

---

### P5 用户侧行为预测与防范
1. **虚拟列表**：使用 `react-virtuoso` 虚拟渲染消息列表，支持动态高度与流式更新，避免长列表卡顿。
2. **缓存协同**：三层加载策略：LocalStorage 秒开（0ms）→ MongoDB 拉最新（~200ms）→ 智能合并无闪更新；配合 LRU 控制 LocalStorage 容量。
3. **数据加密**：AES-GCM + 设备绑定密钥（由设备指纹派生），即使 LocalStorage 被窃取也无法解密。
4. **Markdown 容错**：三层兜底：自动修复截断代码块/表格 → 渲染失败降级备用渲染器 → 保证不白屏。
5. **渐进式传输**：按数据量自动选策略：<10KB 直传；10KB–5MB gzip；>5MB 分片（50KB/片，断点续传）。
6. **渐进式渲染**：超大 Markdown 流式返回时分批渲染：初始仅显示部分内容，用户按需加载更多并展示进度。

---

### P6 LLM 侧行为预测与防范
（待补）
1. **Embedding 缓存节约 token**：将用户输入向量化，通过相似度阈值识别重复问题，直接返回 Redis 缓存响应。
2. **多 Agent 通信协议**：统一 JSON 协议 `AgentOutput`（agent_id/round/content/metadata/timestamp），保证协作稳定可扩展。
3. **JSON 格式修复**：三层修复：jsonrepair（成熟库）→ 自定义正则 → 模型语义兜底，保证讨论不中断。

---

### P7 项目结构
后端借鉴 Java 分层；前端拆分基础组件/业务组件；自定义 hooks 复用重复逻辑（数据类/交互类/应用类）。抽象原则：出现 2 次以上重复逻辑且预期未来会继续复用。