# 面试演讲稿（可照读）——ByteDanceAiAgentProject：把“AI 对话 Demo”做成“可用产品”

> 使用建议：这份稿子偏长，你可以按面试节奏灵活裁剪。  
> 读法建议：先读 **“1 分钟版”**，看面试官表情，再决定展开到 **“3-5 分钟版”** 或 **“技术深挖版”**。  

---

## 0. 开场（10 秒）

面试官你好，我想用我最近做的一个 **AI 对话应用** 来介绍我的项目能力。  
我刻意把它从“能聊天的 Demo”做成“真实用户能用的产品”，重点解决 **流式可靠性、弱网体验、长文本处理、工具调用闭环、多 Agent 协作与状态恢复** 等线上问题。

> **引导提问（钩子）**：如果你对“流式断连怎么恢复”“多步工具调用怎么防止模型跑偏”“多 Agent 状态怎么持久化”感兴趣，我可以展开讲。

---

## 1. 1 分钟版（强对比，先赢第一印象）

很多同类项目的亮点通常是：SSE 流式输出、Markdown 渲染、虚拟列表、接入 LLM。  
我的差异化是：我更像在做一个“线上可用的系统”，而不是功能堆叠。

我主要做了四件事：

1. **流式输出做稳**：我不是简单把模型输出 `push` 到前端，而是做了 **心跳保活、断连检测、背压控制**，保证长回复也不卡、断了也能优雅停止写入。
2. **中断可恢复**：弱网/刷新时，前端支持重试与恢复参数，后端把关键进度和多轮状态持久化，用户不会“等半天白等”。
3. **长文本可交付**：超长输入走分片上传；长文本分析按阶段拆解（耗时的阶段支持续跑，短阶段允许重算），降低超时与失败率。
4. **多步骤工具调用与多 Agent**：工具调用有轮次上限、连续错误熔断、工具历史反馈机制，避免模型在多步骤任务里只做一半；多 Agent 会话状态用 TTL 持久化，支持续聊/续跑。

> **引导提问（钩子）**：如果你想听“我怎么设计 SSE 事件协议/恢复协议”或者“多工具调用怎么做闭环”，我可以继续展开。

---

## 2. 3–5 分钟版（业务型前端视角：体验闭环 + 可靠性兜底）

### 2.1 我解决的真实用户问题是什么？

做 AI 对话类产品，用户最痛的不是“有没有功能”，而是：

- **等待焦虑**：输出慢、首字出现太晚，用户觉得“卡死了”
- **弱网断连**：输出到一半断了，用户只能重发，体验很差
- **长文本不可用**：一贴长内容就超时/崩溃
- **多步骤任务失败**：模型经常“做了第一步就停”，用户要反复纠正

所以我定义了这个项目的核心 KPI：  
**让用户尽快看到有效输出，且在弱网/长文本/多步骤任务下仍保持可用。**

> **引导提问（钩子）**：如果你想问“我怎么衡量卡顿/断连/重试的效果”“怎么设计‘可用’的标准”，我也可以分享我做的工程化指标。

---

### 2.2 流式通信协议：我设计的不是“输出”，是“可控的流”

#### 2.2.1 为什么不是简单 SSE？

很多项目 SSE 是“模型吐一段 → 前端 append 一段”。  
但线上会遇到三个问题：

- **代理空闲超时**：长时间没有数据，连接被中间层断开
- **客户端刷新/中断**：服务端还在写，产生错误日志与资源浪费
- **长回复背压**：前端渲染跟不上，消息堆积造成卡顿

#### 2.2.2 我怎么做（协议 + 端到端策略）

- **心跳事件**：固定间隔发送心跳，防止空闲超时断开
- **安全写入**：检测 `AbortError/ERR_STREAM_PREMATURE_CLOSE`，客户端断开后立即停止写入
- **受控输出（背压）**：根据 pending 字符数切换“打字机模式”和“快速模式”，长回复不拖垮 UI

> **引导提问（钩子）**：你要是问“背压阈值怎么选”“打字机效果怎么不影响性能”，我可以结合我写的 streaming 文档讲具体取舍。

---

### 2.3 中断可恢复：把“断了就重来”变成“断了能续”

我把“可恢复”拆成两类：

1. **短链路恢复**：一次请求的流式输出中断 → 允许自动重试/继续
2. **长链路恢复**：多 Agent / 多步骤工作流 → 允许从第 N 轮继续

实现上我做了两层兜底：

- **前端层**：发送请求时携带 `resumeFromRound / resumeFromChunk` 等恢复参数；遇到 429 队列时走排队与退避。
- **后端层**：关键进度与会话状态持久化（MongoDB + TTL），重连后能从上一次完成的轮次继续。

> **引导提问（钩子）**：如果你想深挖“为什么选择 MongoDB TTL 而不是 Redis”“恢复协议如何保证幂等”，这块我准备了完整的设计说明。

---

### 2.4 长文本处理：我不是只支持“发出去”，而是支持“发得稳”

长文本类问题非常像真实业务：用户可能一次贴几十 KB 文本。

我做了两个关键策略：

- **输入侧分片上传**：超过阈值自动分片，失败可重试，前端可展示进度，不会一次性把请求打爆。
- **处理侧分阶段**：把长文本分析拆成 Split/Map/Reduce/Final，并明确：
  - **最耗时的 Map 阶段要支持断点续传**
  - **Final 阶段可以接受重算**（因为耗时较短，重算更简单且结果更一致）

> **引导提问（钩子）**：你如果问“为什么 Final 不续传”“怎么避免重算造成体验跳变”，我可以按文档的阶段表讲决策过程。

---

### 2.5 多步骤工具调用：让模型“做完事”而不是“聊完天”

同类项目常见问题：用户一句话要求多步（比如“列计划→查方案→更新计划”），模型经常只做第一步就直接回答。

我做的是 **工具调用闭环**：

- **多轮迭代上限**：防止无限循环
- **连续错误熔断**：最多连续 2 次错误就停止，避免越错越跑偏
- **工具历史追踪**：每轮记录工具、参数、结果、成功/失败
- **反馈提示词**：把“已完成步骤/下一步必须调用的工具”拼成反馈消息再喂回模型，引导它完成剩余步骤
- **连接检查器**：客户端断开时立刻停止工具循环，减少资源浪费

> **引导提问（钩子）**：如果你想听“我怎么写 feedback message 才能逼模型继续调用工具”“怎么避免工具注入/参数污染”，我也有相应的策略与文档。

---

### 2.6 多 Agent：不是为了炫技，而是为了“可解释的协作分工”

我做多 Agent 不是“多开几个模型”，而是做一个可控的协作流程：

- 不同 Agent 负责不同角色（比如规划/执行/审阅），让输出更稳定
- 每一轮都保存会话状态，支持从第 N 轮继续
- 对多轮工作流设置超时与上限，避免“无限讨论”

> **引导提问（钩子）**：你要是问“多 Agent 怎么分工”“为什么要存状态、存哪些状态”“怎么控制总耗时”，我可以展开讲我的工作流设计。

---

## 3. 我想让面试官记住的“差异化一句话”

如果用一句话总结我这个项目的差异化：  
**我把 AI 对话的核心难点当成线上系统来做——解决弱网、长文本、长回复背压、多步骤闭环和状态恢复，而不是只做功能展示。**

---

## 4.（刻意引导）你可以怎么问我，我最希望被问到这些

下面这些问题我都准备得比较深，欢迎你挑一个问我：

- **流式与协议**：
  - “SSE 心跳为什么必要？频率怎么选？”
  - “背压怎么检测？怎么避免打字机效果拖垮性能？”
  - “断连后你是继续还是重算？依据是什么？”

- **可靠性与恢复**：
  - “为什么存 MongoDB TTL 而不是 Redis？”
  - “恢复协议如何保证幂等？如何防止重复写入？”
  - “你怎么做超时/熔断，防止工作流跑飞？”

- **长文本**：
  - “分片阈值怎么定？为什么是这个策略？”
  - “Map 阶段续传和 Final 重算的取舍依据？”

- **工具调用 / 多 Agent**：
  - “工具调用怎么保证模型真的去调用，而不是直接回答？”
  - “多 Agent 的协作怎么避免互相打架？如何控制总成本？”

---

## 5. 收尾（10–15 秒）

最后我想强调的是：我做这个项目时，关注点始终是 **用户体验与可用性**，并且用工程手段把不确定性（弱网、长文本、模型多步行为）变成可控系统。  
如果你愿意，我们可以从“流式协议设计”或“多步骤工具调用闭环”里选一个深入聊。


